{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNc92Yz8w3f0",
    "outputId": "b6a525a6-dd04-4c3b-b26a-d975169e49c8"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.8/dist-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.7.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.11.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.13.0+cu116)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (0.14.0+cu116)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence_transformers) (4.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "# Reference: \n",
    "# 1. https://colab.research.google.com/drive/1wm8Z0ui8ZGSXoR50x52GvWMQkfSPPJ-T#scrollTo=SCFXYdbIXguc\n",
    "# 2. https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o#scrollTo=BJR6t_gCQe_x\n",
    "\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "%cd drive/MyDrive\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)                          \n",
    "    np.random.seed(seed)                       \n",
    "    torch.manual_seed(seed)                    \n",
    "    torch.cuda.manual_seed(seed)               \n",
    "    torch.cuda.manual_seed_all(seed)           \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "setup_seed(42)\n",
    "\n",
    "train_df = pd.read_csv(\"binary_classification_training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "wetJ3fahxL2s"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# read in validation file\n",
    "validation_df = pd.read_csv(\"binary_classification_validation_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7M7Z1eTexON7",
    "outputId": "e98b503f-7d46-468d-ce76-8a45c3bcf5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 19)\n",
      "Index(['Unnamed: 0', 'patent_number', 'decision', 'title', 'abstract',\n",
      "       'claims', 'background', 'summary', 'description', 'cpc_label',\n",
      "       'ipc_label', 'filing_date', 'examiner_id', 'output',\n",
      "       'application_invention_type', 'examiner_art_unit',\n",
      "       'small_entity_indicator', 'aia_first_to_file', 'foreign'],\n",
      "      dtype='object')\n",
      "(5000, 19)\n",
      "Index(['Unnamed: 0', 'patent_number', 'decision', 'title', 'abstract',\n",
      "       'claims', 'background', 'summary', 'description', 'cpc_label',\n",
      "       'ipc_label', 'filing_date', 'examiner_id', 'output',\n",
      "       'application_invention_type', 'examiner_art_unit',\n",
      "       'small_entity_indicator', 'aia_first_to_file', 'foreign'],\n",
      "      dtype='object')\n",
      "10000\n",
      "10000\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.columns)\n",
    "print(validation_df.shape)\n",
    "print(validation_df.columns)\n",
    "\n",
    "print(len(train_df[train_df[\"decision\"] == \"ACCEPTED\"]))\n",
    "print(len(train_df[train_df[\"decision\"] == \"REJECTED\"]))\n",
    "print(len(validation_df[validation_df[\"decision\"] == \"ACCEPTED\"]))\n",
    "print(len(validation_df[validation_df[\"decision\"] == \"REJECTED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HRcKkrymxQEr"
   },
   "outputs": [],
   "source": [
    "# Mapping the field output; 1 = ACCEPTED; 0 = REJECTED\n",
    "train_df['output'] = 1\n",
    "train_df.loc[train_df['decision'] == \"REJECTED\", 'output'] = 0\n",
    "\n",
    "validation_df['output'] = 1\n",
    "validation_df.loc[validation_df['decision'] == \"REJECTED\", 'output'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBGhMiQsxTH6",
    "outputId": "90e6f67f-3294-4ff0-8f94-d63fbcc837d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# check Rejected versus Accepted based on output field\n",
    "print(len(train_df[train_df[\"output\"] == 1]))\n",
    "print(len(train_df[train_df[\"output\"] == 0]))\n",
    "print(len(validation_df[validation_df[\"output\"] == 1]))\n",
    "print(len(validation_df[validation_df[\"output\"] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "tyQFT8xmxUtE",
    "outputId": "f71b7618-f956-4a24-8cb9-f643a298f646"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-71bc9179-1aa9-4cc8-84a9-2122ea8282c6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>decision</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>background</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>cpc_label</th>\n",
       "      <th>ipc_label</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>examiner_id</th>\n",
       "      <th>output</th>\n",
       "      <th>application_invention_type</th>\n",
       "      <th>examiner_art_unit</th>\n",
       "      <th>small_entity_indicator</th>\n",
       "      <th>aia_first_to_file</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17944</td>\n",
       "      <td>15187583</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>FULLY INTEGRATED, DISPOSABLE TISSUE VISUALIZAT...</td>\n",
       "      <td>The present invention relates to a fully integ...</td>\n",
       "      <td>1-11. (canceled) 12. A sterilized, integrated,...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;1. Fiel...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;Embodiment...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>A61B107</td>\n",
       "      <td>A61B107</td>\n",
       "      <td>20160620</td>\n",
       "      <td>86346.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>3779</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1686</td>\n",
       "      <td>14906225</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>Compositions and Methods Comprising a Lipolyti...</td>\n",
       "      <td>The present invention provides lipolytic enzym...</td>\n",
       "      <td>1. A lipolytic enzyme variant or an active fra...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Lipolyt...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;The presen...</td>\n",
       "      <td>CROSS REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>C12N920</td>\n",
       "      <td>C12N920</td>\n",
       "      <td>20160119</td>\n",
       "      <td>68762.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1656</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3522</td>\n",
       "      <td>15012119</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>IMAGE DISPLAY DEVICE</td>\n",
       "      <td>An image display device of the present disclos...</td>\n",
       "      <td>1. An image display device comprising: a displ...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;1. Technical Field The p...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY &lt;EOH&gt;An image display device of ...</td>\n",
       "      <td>BACKGROUND 1. Technical Field The present disc...</td>\n",
       "      <td>G02B270172</td>\n",
       "      <td>G02B2701</td>\n",
       "      <td>20160201</td>\n",
       "      <td>99575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2626</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6639</td>\n",
       "      <td>15054201</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>ABUSE-PROOFED DOSAGE FORM</td>\n",
       "      <td>The invention relates to a dosage form that is...</td>\n",
       "      <td>1. An abuse-proofed dosage form thermoformed b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;SOH&gt; BRIEF DESCRIPTION OF THE DRAWING &lt;EOH&gt;FI...</td>\n",
       "      <td>This application is a continuation of U.S. Ser...</td>\n",
       "      <td>A61K31135</td>\n",
       "      <td>A61K31135</td>\n",
       "      <td>20160226</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1615</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18595</td>\n",
       "      <td>15108464</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>Process for the Preparation of Solid Particula...</td>\n",
       "      <td>A novel process for preparing vinyl aromatic p...</td>\n",
       "      <td>1. A process for the preparation of a solid pa...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Expanda...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;The object...</td>\n",
       "      <td>FIELD OF THE INVENTION The present invention r...</td>\n",
       "      <td>C08J920</td>\n",
       "      <td>C08J920</td>\n",
       "      <td>20160627</td>\n",
       "      <td>97379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1765</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71bc9179-1aa9-4cc8-84a9-2122ea8282c6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-71bc9179-1aa9-4cc8-84a9-2122ea8282c6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-71bc9179-1aa9-4cc8-84a9-2122ea8282c6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  patent_number  decision  \\\n",
       "0       17944       15187583  ACCEPTED   \n",
       "1        1686       14906225  REJECTED   \n",
       "2        3522       15012119  REJECTED   \n",
       "3        6639       15054201  REJECTED   \n",
       "4       18595       15108464  ACCEPTED   \n",
       "\n",
       "                                               title  \\\n",
       "0  FULLY INTEGRATED, DISPOSABLE TISSUE VISUALIZAT...   \n",
       "1  Compositions and Methods Comprising a Lipolyti...   \n",
       "2                               IMAGE DISPLAY DEVICE   \n",
       "3                          ABUSE-PROOFED DOSAGE FORM   \n",
       "4  Process for the Preparation of Solid Particula...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The present invention relates to a fully integ...   \n",
       "1  The present invention provides lipolytic enzym...   \n",
       "2  An image display device of the present disclos...   \n",
       "3  The invention relates to a dosage form that is...   \n",
       "4  A novel process for preparing vinyl aromatic p...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  1-11. (canceled) 12. A sterilized, integrated,...   \n",
       "1  1. A lipolytic enzyme variant or an active fra...   \n",
       "2  1. An image display device comprising: a displ...   \n",
       "3  1. An abuse-proofed dosage form thermoformed b...   \n",
       "4  1. A process for the preparation of a solid pa...   \n",
       "\n",
       "                                          background  \\\n",
       "0  <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
       "1  <SOH> BACKGROUND OF THE INVENTION <EOH>Lipolyt...   \n",
       "2  <SOH> BACKGROUND <EOH>1. Technical Field The p...   \n",
       "3                                                NaN   \n",
       "4  <SOH> BACKGROUND OF THE INVENTION <EOH>Expanda...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <SOH> SUMMARY OF THE INVENTION <EOH>Embodiment...   \n",
       "1  <SOH> SUMMARY OF THE INVENTION <EOH>The presen...   \n",
       "2  <SOH> SUMMARY <EOH>An image display device of ...   \n",
       "3  <SOH> BRIEF DESCRIPTION OF THE DRAWING <EOH>FI...   \n",
       "4  <SOH> SUMMARY OF THE INVENTION <EOH>The object...   \n",
       "\n",
       "                                         description   cpc_label  ipc_label  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATIONS This a...     A61B107    A61B107   \n",
       "1  CROSS REFERENCE TO RELATED APPLICATIONS This a...     C12N920    C12N920   \n",
       "2  BACKGROUND 1. Technical Field The present disc...  G02B270172   G02B2701   \n",
       "3  This application is a continuation of U.S. Ser...   A61K31135  A61K31135   \n",
       "4  FIELD OF THE INVENTION The present invention r...     C08J920    C08J920   \n",
       "\n",
       "   filing_date  examiner_id  output application_invention_type  \\\n",
       "0     20160620      86346.0       1                    Utility   \n",
       "1     20160119      68762.0       0                    Utility   \n",
       "2     20160201      99575.0       0                    Utility   \n",
       "3     20160226      66231.0       0                    Utility   \n",
       "4     20160627      97379.0       1                    Utility   \n",
       "\n",
       "  examiner_art_unit small_entity_indicator aia_first_to_file  foreign  \n",
       "0              3779                  SMALL              true    False  \n",
       "1              1656           UNDISCOUNTED              true    False  \n",
       "2              2626           UNDISCOUNTED              true     True  \n",
       "3              1615           UNDISCOUNTED             false     True  \n",
       "4              1765           UNDISCOUNTED              true     True  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check train_df\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "72oz2ZnnxWaL",
    "outputId": "fefe4891-5a15-41f3-cbce-b03b379762d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1ca68efa-6a0c-427a-9e4c-52ac3ac79f85\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>decision</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>background</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>cpc_label</th>\n",
       "      <th>ipc_label</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>examiner_id</th>\n",
       "      <th>output</th>\n",
       "      <th>application_invention_type</th>\n",
       "      <th>examiner_art_unit</th>\n",
       "      <th>small_entity_indicator</th>\n",
       "      <th>aia_first_to_file</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>15227186</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>IMAGING DEVICE AND FOCUSING CONTROL METHOD</td>\n",
       "      <td>The present invention provides an imaging devi...</td>\n",
       "      <td>1. An imaging device comprising: an imaging el...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;1. Fiel...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;In all of ...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>H04N523212</td>\n",
       "      <td>H04N5232</td>\n",
       "      <td>20160803</td>\n",
       "      <td>70534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003</td>\n",
       "      <td>15129780</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>FOIL REMOVAL DEVICE AND A METHOD FOR REMOVING ...</td>\n",
       "      <td>Provided is a foil removal device and a method...</td>\n",
       "      <td>1-26. (canceled) 27. A foil removal device for...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;The invention relates to...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;According ...</td>\n",
       "      <td>BACKGROUND The invention relates to a foil rem...</td>\n",
       "      <td>B65H19286</td>\n",
       "      <td>B65H1928</td>\n",
       "      <td>20160927</td>\n",
       "      <td>61755.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>811</td>\n",
       "      <td>15234229</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>FUNGICIDAL COMPOSITION COMPRISING A PYRIDYLETH...</td>\n",
       "      <td>A composition comprising at least a pyridyleth...</td>\n",
       "      <td>1.-20. (canceled) 21. A composition comprising...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Interna...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;Accordingl...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION(S) The ...</td>\n",
       "      <td>A01N4340</td>\n",
       "      <td>A01N4340</td>\n",
       "      <td>20160811</td>\n",
       "      <td>62399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624</td>\n",
       "      <td>15233691</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>SEMICONDUCTOR MEMORY DEVICE</td>\n",
       "      <td>A semiconductor memory device includes a plura...</td>\n",
       "      <td>1. A semiconductor memory device comprising: a...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;A NAND type flash memory...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION This ap...</td>\n",
       "      <td>G11C160483</td>\n",
       "      <td>G11C1604</td>\n",
       "      <td>20160810</td>\n",
       "      <td>62558.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3125</td>\n",
       "      <td>15125628</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>METHODS AND SYSTEMS FOR AUTOMATIC CREATION OF ...</td>\n",
       "      <td>Disclosed herein are methods and systems for a...</td>\n",
       "      <td>1. A method comprising: a first mobile radio b...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Million...</td>\n",
       "      <td>&lt;SOH&gt; BRIEF DESCRIPTION OF THE SEVERAL VIEWS O...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION Millions of people...</td>\n",
       "      <td>H04W408</td>\n",
       "      <td>H04W408</td>\n",
       "      <td>20160913</td>\n",
       "      <td>62652.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ca68efa-6a0c-427a-9e4c-52ac3ac79f85')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1ca68efa-6a0c-427a-9e4c-52ac3ac79f85 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1ca68efa-6a0c-427a-9e4c-52ac3ac79f85');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  patent_number  decision  \\\n",
       "0         149       15227186  ACCEPTED   \n",
       "1        4003       15129780  ACCEPTED   \n",
       "2         811       15234229  REJECTED   \n",
       "3         624       15233691  REJECTED   \n",
       "4        3125       15125628  ACCEPTED   \n",
       "\n",
       "                                               title  \\\n",
       "0         IMAGING DEVICE AND FOCUSING CONTROL METHOD   \n",
       "1  FOIL REMOVAL DEVICE AND A METHOD FOR REMOVING ...   \n",
       "2  FUNGICIDAL COMPOSITION COMPRISING A PYRIDYLETH...   \n",
       "3                        SEMICONDUCTOR MEMORY DEVICE   \n",
       "4  METHODS AND SYSTEMS FOR AUTOMATIC CREATION OF ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The present invention provides an imaging devi...   \n",
       "1  Provided is a foil removal device and a method...   \n",
       "2  A composition comprising at least a pyridyleth...   \n",
       "3  A semiconductor memory device includes a plura...   \n",
       "4  Disclosed herein are methods and systems for a...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  1. An imaging device comprising: an imaging el...   \n",
       "1  1-26. (canceled) 27. A foil removal device for...   \n",
       "2  1.-20. (canceled) 21. A composition comprising...   \n",
       "3  1. A semiconductor memory device comprising: a...   \n",
       "4  1. A method comprising: a first mobile radio b...   \n",
       "\n",
       "                                          background  \\\n",
       "0  <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
       "1  <SOH> BACKGROUND <EOH>The invention relates to...   \n",
       "2  <SOH> BACKGROUND OF THE INVENTION <EOH>Interna...   \n",
       "3  <SOH> BACKGROUND <EOH>A NAND type flash memory...   \n",
       "4  <SOH> BACKGROUND OF THE INVENTION <EOH>Million...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <SOH> SUMMARY OF THE INVENTION <EOH>In all of ...   \n",
       "1  <SOH> SUMMARY OF THE INVENTION <EOH>According ...   \n",
       "2  <SOH> SUMMARY OF THE INVENTION <EOH>Accordingl...   \n",
       "3                                                NaN   \n",
       "4  <SOH> BRIEF DESCRIPTION OF THE SEVERAL VIEWS O...   \n",
       "\n",
       "                                         description   cpc_label ipc_label  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  H04N523212  H04N5232   \n",
       "1  BACKGROUND The invention relates to a foil rem...   B65H19286  B65H1928   \n",
       "2  CROSS-REFERENCE TO RELATED APPLICATION(S) The ...    A01N4340  A01N4340   \n",
       "3  CROSS-REFERENCE TO RELATED APPLICATION This ap...  G11C160483  G11C1604   \n",
       "4  BACKGROUND OF THE INVENTION Millions of people...     H04W408   H04W408   \n",
       "\n",
       "   filing_date  examiner_id  output application_invention_type  \\\n",
       "0     20160803      70534.0       1                    Utility   \n",
       "1     20160927      61755.0       1                    Utility   \n",
       "2     20160811      62399.0       0                    Utility   \n",
       "3     20160810      62558.0       0                    Utility   \n",
       "4     20160913      62652.0       1                    Utility   \n",
       "\n",
       "   examiner_art_unit small_entity_indicator aia_first_to_file  foreign  \n",
       "0             2662.0           UNDISCOUNTED              true     True  \n",
       "1             1745.0           UNDISCOUNTED              true     True  \n",
       "2             1627.0           UNDISCOUNTED             false     True  \n",
       "3             2824.0           UNDISCOUNTED              true     True  \n",
       "4             2648.0           UNDISCOUNTED              true    False  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check train_df\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UInVWITx0mOt",
    "outputId": "b93f2620-3ae4-49fd-b178-e80136eeb160"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'patent_number', 'decision', 'title', 'abstract',\n",
      "       'claims', 'background', 'summary', 'description', 'cpc_label',\n",
      "       'ipc_label', 'filing_date', 'examiner_id', 'output',\n",
      "       'application_invention_type', 'examiner_art_unit',\n",
      "       'small_entity_indicator', 'aia_first_to_file', 'foreign'],\n",
      "      dtype='object')\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "print((train_df[\"cpc_label\"] == None).sum()) \n",
    "print((train_df[\"ipc_label\"] == None).sum()) \n",
    "print((train_df[\"filing_date\"] == None).sum()) \n",
    "print((train_df[\"examiner_id\"] == None).sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "RKHx9G11rdaq",
    "outputId": "605cf1b4-da99-40b5-9c61-656eb71b77e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7458d4b0-38a2-4369-8145-f0ef6b04e126\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>decision</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>background</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>cpc_label</th>\n",
       "      <th>...</th>\n",
       "      <th>examiner_art_unit</th>\n",
       "      <th>small_entity_indicator</th>\n",
       "      <th>aia_first_to_file</th>\n",
       "      <th>foreign</th>\n",
       "      <th>small_entity_indicator_dict_value</th>\n",
       "      <th>aia_first_to_file_dict_value</th>\n",
       "      <th>foreign_dict_value</th>\n",
       "      <th>ipc_label_value</th>\n",
       "      <th>filing_month_value</th>\n",
       "      <th>examiner_art_unit_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7458d4b0-38a2-4369-8145-f0ef6b04e126')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7458d4b0-38a2-4369-8145-f0ef6b04e126 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7458d4b0-38a2-4369-8145-f0ef6b04e126');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, patent_number, decision, title, abstract, claims, background, summary, description, cpc_label, ipc_label, filing_date, examiner_id, output, application_invention_type, examiner_art_unit, small_entity_indicator, aia_first_to_file, foreign, small_entity_indicator_dict_value, aia_first_to_file_dict_value, foreign_dict_value, ipc_label_value, filing_month_value, examiner_art_unit_value]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify Train and Validation\n",
    "\n",
    "small_entity_indicator_dict = {\n",
    "    'SMALL': 0, \n",
    "    'UNDISCOUNTED': 1, \n",
    "    'MICRO': 2\n",
    "}\n",
    "\n",
    "aia_first_to_file_dict = {\n",
    "    'false': 0, \n",
    "    'true': 1, \n",
    "    'Other': 2\n",
    "}\n",
    "\n",
    "foreign_dict = {\n",
    "    False : 0, \n",
    "    True: 1,     \n",
    "}\n",
    "\n",
    "decision_to_str = {\n",
    "    'REJECTED': 0, \n",
    "    'ACCEPTED': 1, \n",
    "}\n",
    "\n",
    "# TRAIN_DF \n",
    "train_df_examiner_unit = pd.DataFrame(train_df[\"examiner_art_unit\"].unique(), columns = ['examiner_art_unit'])\n",
    "train_df['small_entity_indicator_dict_value'] = train_df['small_entity_indicator'].map(small_entity_indicator_dict)\n",
    "train_df['aia_first_to_file_dict_value'] = train_df['aia_first_to_file'].map(aia_first_to_file_dict)\n",
    "train_df['foreign_dict_value'] = train_df['foreign'].map(foreign_dict)\n",
    "train_df['ipc_label_value'] = train_df['ipc_label'].str[:4]\n",
    "train_df['output'] = train_df['decision'].map(decision_to_str)\n",
    "train_df['filing_month_value'] = train_df['filing_date'].astype(str).str[4:6]\n",
    "\n",
    "# join the examiner art unit column\n",
    "train_df['examiner_art_unit_value'] = train_df.examiner_art_unit.astype(\"category\").cat.codes\n",
    "# spot check\n",
    "train_df[train_df['examiner_art_unit_value'] == 595]\n",
    "\n",
    "\n",
    "# VALIDATION_DF\n",
    "validation_df_examiner_unit = pd.DataFrame(validation_df[\"examiner_art_unit\"].unique(), columns = ['examiner_art_unit'])\n",
    "validation_df['small_entity_indicator_dict_value'] = validation_df['small_entity_indicator'].map(small_entity_indicator_dict)\n",
    "validation_df['aia_first_to_file_dict_value'] = validation_df['aia_first_to_file'].map(aia_first_to_file_dict)\n",
    "validation_df['foreign_dict_value'] = validation_df['foreign'].map(foreign_dict)\n",
    "validation_df['output'] = validation_df['decision'].map(decision_to_str)\n",
    "validation_df['ipc_label_value'] = validation_df['ipc_label'].str[:4]\n",
    "validation_df['filing_month_value'] = validation_df['filing_date'].astype(str).str[4:6]\n",
    "\n",
    "# join the examiner art unit column\n",
    "validation_df['examiner_art_unit_value'] = validation_df.examiner_art_unit.astype(\"category\").cat.codes\n",
    "# spot check\n",
    "validation_df[validation_df['examiner_art_unit_value'] == 595]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3OCD-IbsW4a",
    "outputId": "5868af25-3943-4044-dac0-486274b4c826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['06', '01', '02', '03', '04', '05', '07'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check\n",
    "train_df['filing_month_value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7culYsVsaYK",
    "outputId": "3f1ee161-56f3-452b-bc7d-4b845c1ef9d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['08', '09', '07', '10'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check\n",
    "validation_df['filing_month_value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TEgncEbJuBG9"
   },
   "outputs": [],
   "source": [
    "# convert and add another column of one_hot encoding\n",
    "train_df[\"output_onehot\"] = pd.get_dummies(train_df[\"output\"]).values.tolist()\n",
    "validation_df[\"output_onehot\"] = pd.get_dummies(validation_df[\"output\"]).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh0mNh3cxX6U",
    "outputId": "99101ba6-121f-4afb-aec1-175f8ea580e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           claims_mod  Unnamed: 0  \\\n",
      "0   [1. (canceled), A sterilized, integrated, one ...       17944   \n",
      "1   [A lipolytic enzyme variant or an active fragm...        1686   \n",
      "2   [An image display device comprising: a display...        3522   \n",
      "3   [An abuse-proofed dosage form thermoformed by ...        6639   \n",
      "4   [A process for the preparation of a solid part...       18595   \n",
      "5   [. (canceled), A bonded magnet comprising the ...        7294   \n",
      "6   [20. (canceled), A surgical device, comprising...        2903   \n",
      "7   [A remote node (RN) comprising: a downstream p...       18753   \n",
      "8   [A system for full motion capture and haptic f...       13371   \n",
      "9   [22. (canceled), A device comprising a scaffol...       12593   \n",
      "10  [A method for manufacturing a motor bobbin aro...        6759   \n",
      "11  [A display device comprising: a transistor com...       11653   \n",
      "12  [A method for securing an implant to a bone of...        7226   \n",
      "13  [A method for operating a fuel injector of an ...        3837   \n",
      "14  [(canceled), A method for the treatment of non...        8424   \n",
      "15  [A powder comprising at least one cosmetic pow...       10140   \n",
      "16  [A carrier assembly comprising: a plurality of...       17668   \n",
      "17  [A mirror assembly adapted for use in a panora...         872   \n",
      "18  [A child receptacle cover for use with an appa...       13909   \n",
      "19  [A process for purifying graphene nanoribbons,...        6338   \n",
      "\n",
      "    patent_number  decision  \\\n",
      "0        15187583  ACCEPTED   \n",
      "1        14906225  REJECTED   \n",
      "2        15012119  REJECTED   \n",
      "3        15054201  REJECTED   \n",
      "4        15108464  ACCEPTED   \n",
      "5        15059906  REJECTED   \n",
      "6        15008530  ACCEPTED   \n",
      "7        15195529  REJECTED   \n",
      "8        15141564  REJECTED   \n",
      "9        15135290  REJECTED   \n",
      "10       14915459  ACCEPTED   \n",
      "11       15096793  ACCEPTED   \n",
      "12       15059511  REJECTED   \n",
      "13       15014660  REJECTED   \n",
      "14       15069355  ACCEPTED   \n",
      "15       15084071  REJECTED   \n",
      "16       15183867  ACCEPTED   \n",
      "17       14992500  REJECTED   \n",
      "18       15147278  REJECTED   \n",
      "19       14914558  REJECTED   \n",
      "\n",
      "                                                title  \\\n",
      "0   FULLY INTEGRATED, DISPOSABLE TISSUE VISUALIZAT...   \n",
      "1   Compositions and Methods Comprising a Lipolyti...   \n",
      "2                                IMAGE DISPLAY DEVICE   \n",
      "3                           ABUSE-PROOFED DOSAGE FORM   \n",
      "4   Process for the Preparation of Solid Particula...   \n",
      "5   FERROMAGNETIC PARTICLES AND PROCESS FOR PRODUC...   \n",
      "6   SURGICAL INSTRUMENT WITH ULTRASONIC TRANSDUCER...   \n",
      "7   Optical Network Unit (ONU) Wavelength Self-Tuning   \n",
      "8   System and Method for Full Motion Capture and ...   \n",
      "9                 Continuous Cell Programming Devices   \n",
      "10     MOTOR BOBBIN AND METHOD FOR MANUFACTURING SAME   \n",
      "11                                     Display Device   \n",
      "12          BONE IMPLANT AUGMENT METHOD AND APPARATUS   \n",
      "13               METHOD FOR OPERATING A FUEL INJECTOR   \n",
      "14  IBAT INHIBITORS FOR THE TREATMENT OF LIVER DIS...   \n",
      "15  COSMETIC POWDER TREATED WITH POLYSACCHARIDE AN...   \n",
      "16  Optoelectronic Semiconductor Apparatus and Car...   \n",
      "17          SYSTEMS AND METHODS FOR PANORAMIC IMAGING   \n",
      "18                             Child Receptacle Cover   \n",
      "19      PURIFICATION PROCESS FOR GRAPHENE NANORIBBONS   \n",
      "\n",
      "                                             abstract  \\\n",
      "0   The present invention relates to a fully integ...   \n",
      "1   The present invention provides lipolytic enzym...   \n",
      "2   An image display device of the present disclos...   \n",
      "3   The invention relates to a dosage form that is...   \n",
      "4   A novel process for preparing vinyl aromatic p...   \n",
      "5   The present invention relates to Fe16N2 partic...   \n",
      "6   An ultrasonic surgical device comprises a hand...   \n",
      "7   A remote node (RN) comprises a downstream port...   \n",
      "8   A full motion capture and haptic feedback suit...   \n",
      "9   The present invention comprises compositions, ...   \n",
      "10  In a method for manufacturing a motor bobbin a...   \n",
      "11  To provide a display device in which variation...   \n",
      "12  An offset of a bone implant relative to a bone...   \n",
      "13  A method for operating a fuel injector, in par...   \n",
      "14  The present invention regards specific IBAT in...   \n",
      "15  The present disclosure relates generally to co...   \n",
      "16  A semiconductor apparatus with an optoelectron...   \n",
      "17  Systems and methods for panoramic imaging are ...   \n",
      "18  A child receptacle cover for use with an appar...   \n",
      "19  In a process for purifying graphene nanoribbon...   \n",
      "\n",
      "                                               claims  \\\n",
      "0   1-11. (canceled) 12. A sterilized, integrated,...   \n",
      "1   1. A lipolytic enzyme variant or an active fra...   \n",
      "2   1. An image display device comprising: a displ...   \n",
      "3   1. An abuse-proofed dosage form thermoformed b...   \n",
      "4   1. A process for the preparation of a solid pa...   \n",
      "5   1-9. (canceled) 10. A bonded magnet comprising...   \n",
      "6   1.-20. (canceled) 21. A surgical device, compr...   \n",
      "7   1. A remote node (RN) comprising: a downstream...   \n",
      "8   1. A system for full motion capture and haptic...   \n",
      "9   1.-22. (canceled) 23. A device comprising a sc...   \n",
      "10  1. A method for manufacturing a motor bobbin a...   \n",
      "11  1. A display device comprising: a transistor c...   \n",
      "12  1. A method for securing an implant to a bone ...   \n",
      "13  1. A method for operating a fuel injector of a...   \n",
      "14  1. (canceled) 2. A method for the treatment of...   \n",
      "15  1. A powder comprising at least one cosmetic p...   \n",
      "16  1. A carrier assembly comprising: a plurality ...   \n",
      "17  1. A mirror assembly adapted for use in a pano...   \n",
      "18  1. A child receptacle cover for use with an ap...   \n",
      "19  1. A process for purifying graphene nanoribbon...   \n",
      "\n",
      "                                           background  \\\n",
      "0   <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
      "1   <SOH> BACKGROUND OF THE INVENTION <EOH>Lipolyt...   \n",
      "2   <SOH> BACKGROUND <EOH>1. Technical Field The p...   \n",
      "3                                                 NaN   \n",
      "4   <SOH> BACKGROUND OF THE INVENTION <EOH>Expanda...   \n",
      "5   <SOH> BACKGROUND ART <EOH>At present, various ...   \n",
      "6   <SOH> BACKGROUND <EOH>In some settings, endosc...   \n",
      "7   <SOH> BACKGROUND <EOH>A passive optical networ...   \n",
      "8   <SOH> BACKGROUND OF THE INVENTION <EOH>The mar...   \n",
      "9   <SOH> BACKGROUND OF THE INVENTION <EOH>Dendrit...   \n",
      "10  <SOH> BACKGROUND ART <EOH>A motor generator fu...   \n",
      "11  <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
      "12  <SOH> BACKGROUND <EOH>The proper functioning o...   \n",
      "13  <SOH> BACKGROUND INFORMATION <EOH>The present ...   \n",
      "14  <SOH> BACKGROUND OF THE INVENTION <EOH>Ileal b...   \n",
      "15  <SOH> BACKGROUND <EOH>The information provided...   \n",
      "16  <SOH> BACKGROUND <EOH>Optoelectronic semicondu...   \n",
      "17  <SOH> BACKGROUND <EOH>1. Field The present app...   \n",
      "18  <SOH> BACKGROUND <EOH>Traditionally, car seat ...   \n",
      "19                                                NaN   \n",
      "\n",
      "                                              summary  \\\n",
      "0   <SOH> SUMMARY OF THE INVENTION <EOH>Embodiment...   \n",
      "1   <SOH> SUMMARY OF THE INVENTION <EOH>The presen...   \n",
      "2   <SOH> SUMMARY <EOH>An image display device of ...   \n",
      "3   <SOH> BRIEF DESCRIPTION OF THE DRAWING <EOH>FI...   \n",
      "4   <SOH> SUMMARY OF THE INVENTION <EOH>The object...   \n",
      "5                <SOH> SUMMARY OF THE INVENTION <EOH>   \n",
      "6   <SOH> BRIEF DESCRIPTION OF THE DRAWINGS <EOH>W...   \n",
      "7   <SOH> SUMMARY <EOH>In one embodiment, the disc...   \n",
      "8   <SOH> SUMMARY OF THE INVENTION <EOH>The presen...   \n",
      "9   <SOH> SUMMARY OF THE INVENTION <EOH>The invent...   \n",
      "10  <SOH> SUMMARY OF INVENTION <EOH>An object of t...   \n",
      "11  <SOH> SUMMARY OF THE INVENTION <EOH>A pixel wh...   \n",
      "12  <SOH> SUMMARY OF THE INVENTION <EOH>The invent...   \n",
      "13  <SOH> SUMMARY <EOH>An example method according...   \n",
      "14  <SOH> SUMMARY OF THE INVENTION <EOH>The presen...   \n",
      "15  <SOH> SUMMARY OF INVENTION <EOH>The embodiment...   \n",
      "16  <SOH> SUMMARY <EOH>According to at least one e...   \n",
      "17  <SOH> SUMMARY <EOH>Systems and methods for cap...   \n",
      "18  <SOH> SUMMARY <EOH>A first aspect is a child r...   \n",
      "19                                                NaN   \n",
      "\n",
      "                                          description  ...  \\\n",
      "0   CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "1   CROSS REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "2   BACKGROUND 1. Technical Field The present disc...  ...   \n",
      "3   This application is a continuation of U.S. Ser...  ...   \n",
      "4   FIELD OF THE INVENTION The present invention r...  ...   \n",
      "5   TECHNICAL FIELD The present invention relates ...  ...   \n",
      "6   PRIORITY This application claims priority to U...  ...   \n",
      "7   CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "8   CROSS REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "9   RELATED APPLICATIONS This application is a con...  ...   \n",
      "10  TECHNICAL FIELD The present invention relates ...  ...   \n",
      "11  BACKGROUND OF THE INVENTION 1. Field of the In...  ...   \n",
      "12  CROSS REFERENCE TO RELATED APPLICATIONS This p...  ...   \n",
      "13  CROSS REFERENCE The present application claims...  ...   \n",
      "14  BACKGROUND OF THE INVENTION Ileal bile acid tr...  ...   \n",
      "15  FIELD OF THE INVENTION The present disclosure ...  ...   \n",
      "16  CROSS-REFERENCE TO RELATED APPLICATIONS This p...  ...   \n",
      "17  CROSS REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "18  RELATED APPLICATIONS This application claims p...  ...   \n",
      "19  The present invention relates to a purificatio...  ...   \n",
      "\n",
      "   small_entity_indicator aia_first_to_file  foreign  \\\n",
      "0                   SMALL              true    False   \n",
      "1            UNDISCOUNTED              true    False   \n",
      "2            UNDISCOUNTED              true     True   \n",
      "3            UNDISCOUNTED             false     True   \n",
      "4            UNDISCOUNTED              true     True   \n",
      "5            UNDISCOUNTED             false     True   \n",
      "6            UNDISCOUNTED             false    False   \n",
      "7            UNDISCOUNTED              true    False   \n",
      "8                   MICRO              true    False   \n",
      "9                   SMALL             false    False   \n",
      "10           UNDISCOUNTED              true     True   \n",
      "11           UNDISCOUNTED              true     True   \n",
      "12                  SMALL              true    False   \n",
      "13           UNDISCOUNTED              true     True   \n",
      "14                  SMALL             false     True   \n",
      "15           UNDISCOUNTED              true    False   \n",
      "16           UNDISCOUNTED             false     True   \n",
      "17                  SMALL             false    False   \n",
      "18                  MICRO              true    False   \n",
      "19           UNDISCOUNTED              true     True   \n",
      "\n",
      "    small_entity_indicator_dict_value  aia_first_to_file_dict_value  \\\n",
      "0                                   0                             1   \n",
      "1                                   1                             1   \n",
      "2                                   1                             1   \n",
      "3                                   1                             0   \n",
      "4                                   1                             1   \n",
      "5                                   1                             0   \n",
      "6                                   1                             0   \n",
      "7                                   1                             1   \n",
      "8                                   2                             1   \n",
      "9                                   0                             0   \n",
      "10                                  1                             1   \n",
      "11                                  1                             1   \n",
      "12                                  0                             1   \n",
      "13                                  1                             1   \n",
      "14                                  0                             0   \n",
      "15                                  1                             1   \n",
      "16                                  1                             0   \n",
      "17                                  0                             0   \n",
      "18                                  2                             1   \n",
      "19                                  1                             1   \n",
      "\n",
      "   foreign_dict_value ipc_label_value filing_month_value  \\\n",
      "0                   0            A61B                 06   \n",
      "1                   0            C12N                 01   \n",
      "2                   1            G02B                 02   \n",
      "3                   1            A61K                 02   \n",
      "4                   1            C08J                 06   \n",
      "5                   1            H01F                 03   \n",
      "6                   0            A61N                 01   \n",
      "7                   0            H04Q                 06   \n",
      "8                   0            G06F                 04   \n",
      "9                   0            A61K                 04   \n",
      "10                  1            B29C                 02   \n",
      "11                  1            H01L                 04   \n",
      "12                  0            A61F                 03   \n",
      "13                  1            F02D                 02   \n",
      "14                  1            A61K                 03   \n",
      "15                  0            A61K                 03   \n",
      "16                  1            H01L                 06   \n",
      "17                  0            G02B                 01   \n",
      "18                  0            A47D                 05   \n",
      "19                  1            C01B                 02   \n",
      "\n",
      "   examiner_art_unit_value  output_onehot  \n",
      "0                      595         [0, 1]  \n",
      "1                       47         [1, 0]  \n",
      "2                      306         [1, 0]  \n",
      "3                        3         [1, 0]  \n",
      "4                      111         [0, 1]  \n",
      "5                      132         [1, 0]  \n",
      "6                      585         [0, 1]  \n",
      "7                      315         [1, 0]  \n",
      "8                      306         [1, 0]  \n",
      "9                       38         [1, 0]  \n",
      "10                     390         [0, 1]  \n",
      "11                     438         [0, 1]  \n",
      "12                     559         [1, 0]  \n",
      "13                     569         [1, 0]  \n",
      "14                      19         [0, 1]  \n",
      "15                       7         [1, 0]  \n",
      "16                     443         [0, 1]  \n",
      "17                     281         [1, 0]  \n",
      "18                     471         [1, 0]  \n",
      "19                      88         [1, 0]  \n",
      "\n",
      "[20 rows x 27 columns]\n",
      "<class 'list'>\n",
      "--------------------------------------------------------------------\n",
      "                                           claims_mod  Unnamed: 0  \\\n",
      "0   [An imaging device comprising: an imaging elem...         149   \n",
      "1   [6. (canceled), A foil removal device for remo...        4003   \n",
      "2   [20. (canceled), A composition comprising: a p...         811   \n",
      "3   [A semiconductor memory device comprising: a p...         624   \n",
      "4   [A method comprising: a first mobile radio bro...        3125   \n",
      "5   [An active implantable medical device (AIMD) f...         214   \n",
      "6   [A rolling bearing with a seal comprising: an ...        1592   \n",
      "7   [An information processing apparatus comprisin...       20808   \n",
      "8   [An information processing system comprising a...        2474   \n",
      "9   [A voltage monitoring system that monitors eac...        2408   \n",
      "10  [(canceled), A method implemented in a crude o...        1384   \n",
      "11  [A seat cushion comprising: a flexible polymer...        2565   \n",
      "12  [A measurement method for in-line measurements...         230   \n",
      "13  [A deployable plug system comprising: a handle...       19688   \n",
      "14  [A method for performing network allocation ve...        1950   \n",
      "15  [A method comprising: at a system configured t...       20851   \n",
      "16  [A sheet feeder comprising: a motor; a feed ro...        2746   \n",
      "17  [Apparatus for exposing a sample, wherein said...       20886   \n",
      "18  [. (canceled), An aqueous liquid composition h...        1064   \n",
      "19  [A compound having the general formula (I), op...        3282   \n",
      "\n",
      "    patent_number  decision  \\\n",
      "0        15227186  ACCEPTED   \n",
      "1        15129780  ACCEPTED   \n",
      "2        15234229  REJECTED   \n",
      "3        15233691  REJECTED   \n",
      "4        15125628  ACCEPTED   \n",
      "5        15229110  ACCEPTED   \n",
      "6        15120769  REJECTED   \n",
      "7        15221020  ACCEPTED   \n",
      "8        15254406  ACCEPTED   \n",
      "9        15254698  REJECTED   \n",
      "10       15242115  ACCEPTED   \n",
      "11       15256181  REJECTED   \n",
      "12       15228772  ACCEPTED   \n",
      "13       15208235  REJECTED   \n",
      "14       15247560  REJECTED   \n",
      "15       15221825  ACCEPTED   \n",
      "16       15258617  ACCEPTED   \n",
      "17       15222708  REJECTED   \n",
      "18       15238385  ACCEPTED   \n",
      "19       15266272  REJECTED   \n",
      "\n",
      "                                                title  \\\n",
      "0          IMAGING DEVICE AND FOCUSING CONTROL METHOD   \n",
      "1   FOIL REMOVAL DEVICE AND A METHOD FOR REMOVING ...   \n",
      "2   FUNGICIDAL COMPOSITION COMPRISING A PYRIDYLETH...   \n",
      "3                         SEMICONDUCTOR MEMORY DEVICE   \n",
      "4   METHODS AND SYSTEMS FOR AUTOMATIC CREATION OF ...   \n",
      "5   IMPLANTABLE MEDICAL DEVICE HAVING ELECTROMAGNE...   \n",
      "6                           ROLLING BEARING WITH SEAL   \n",
      "7   INFORMATION PROCESSING APPARATUS, PROGRAM, AND...   \n",
      "8   INFORMATION PROCESSING SYSTEM, INFORMATION PRO...   \n",
      "9                           VOLTAGE MONITORING SYSTEM   \n",
      "10  RECOVERY AND RE-USE OF WASTE ENERGY IN INDUSTR...   \n",
      "11  SEATING SYSTEM HAVING PRESSURE COMPENSATING FL...   \n",
      "12  MEASUREMENT SYSTEM AND METHOD FOR MEASURING IN...   \n",
      "13                             DEPLOYABLE PLUG SYSTEM   \n",
      "14  METHOD, DEVICE AND SYSTEM FOR PERFORMING NAV C...   \n",
      "15               Predictive Media Distribution System   \n",
      "16  SHEET TRANSPORTING APPARATUS AND IMAGE FORMING...   \n",
      "17  APPARATUS AND METHOD FOR PROCESSING OR IMAGING...   \n",
      "18  FLUOROIONOMERS DISPERSIONS HAVING A LOW SURFAC...   \n",
      "19  Triazolones derivatives and their use in the t...   \n",
      "\n",
      "                                             abstract  \\\n",
      "0   The present invention provides an imaging devi...   \n",
      "1   Provided is a foil removal device and a method...   \n",
      "2   A composition comprising at least a pyridyleth...   \n",
      "3   A semiconductor memory device includes a plura...   \n",
      "4   Disclosed herein are methods and systems for a...   \n",
      "5   An active implantable medical device (AIMD) fo...   \n",
      "6   The slinger is arranged at an axially outermor...   \n",
      "7   There is provided an information processing ap...   \n",
      "8   An information processing device includes: a c...   \n",
      "9   A voltage monitoring system includes a first c...   \n",
      "10  Configurations and related processing schemes ...   \n",
      "11  A seating system, particularly suited for pers...   \n",
      "12  A measurement method and system are presented ...   \n",
      "13  A deployable plug system comprises a handle as...   \n",
      "14  The present invention discloses a method, a de...   \n",
      "15  A disclosed method is performed at a system co...   \n",
      "16  A sheet transporting apparatus is provided, in...   \n",
      "17  The invention relates to an apparatus and meth...   \n",
      "18  The invention pertains to a process for manufa...   \n",
      "19  The present invention relates to a compound ha...   \n",
      "\n",
      "                                               claims  \\\n",
      "0   1. An imaging device comprising: an imaging el...   \n",
      "1   1-26. (canceled) 27. A foil removal device for...   \n",
      "2   1.-20. (canceled) 21. A composition comprising...   \n",
      "3   1. A semiconductor memory device comprising: a...   \n",
      "4   1. A method comprising: a first mobile radio b...   \n",
      "5   1. An active implantable medical device (AIMD)...   \n",
      "6   1. A rolling bearing with a seal comprising: a...   \n",
      "7   1. An information processing apparatus compris...   \n",
      "8   1. An information processing system comprising...   \n",
      "9   1. A voltage monitoring system that monitors e...   \n",
      "10  1. (canceled) 2. A method implemented in a cru...   \n",
      "11  1. A seat cushion comprising: a flexible polym...   \n",
      "12  1. A measurement method for in-line measuremen...   \n",
      "13  1. A deployable plug system comprising: a hand...   \n",
      "14  1. A method for performing network allocation ...   \n",
      "15  1. A method comprising: at a system configured...   \n",
      "16  1. A sheet feeder comprising: a motor; a feed ...   \n",
      "17  1. Apparatus for exposing a sample, wherein sa...   \n",
      "18  1-4. (canceled) 5. An aqueous liquid compositi...   \n",
      "19  1. A compound having the general formula (I), ...   \n",
      "\n",
      "                                           background  \\\n",
      "0   <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
      "1   <SOH> BACKGROUND <EOH>The invention relates to...   \n",
      "2   <SOH> BACKGROUND OF THE INVENTION <EOH>Interna...   \n",
      "3   <SOH> BACKGROUND <EOH>A NAND type flash memory...   \n",
      "4   <SOH> BACKGROUND OF THE INVENTION <EOH>Million...   \n",
      "5   <SOH> BACKGROUND OF THE INVENTION <EOH>Active ...   \n",
      "6   <SOH> TECHNICAL FIELD <EOH>The present inventi...   \n",
      "7   <SOH> BACKGROUND <EOH>The present disclosure r...   \n",
      "8   <SOH> BACKGROUND AND SUMMARY <EOH>Conventional...   \n",
      "9   <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
      "10  <SOH> BACKGROUND <EOH>Petroleum refining proce...   \n",
      "11  <SOH> BACKGROUND OF THE INVENTION <EOH>This in...   \n",
      "12  <SOH> BACKGROUND <EOH>Advanced semiconductor i...   \n",
      "13  <SOH> BACKGROUND <EOH>Bodies of water are high...   \n",
      "14  <SOH> BACKGROUND <EOH>A basic component of a w...   \n",
      "15  <SOH> BACKGROUND <EOH>Modern computing often i...   \n",
      "16  <SOH> BACKGROUND OF THE INVENTION <EOH>Field o...   \n",
      "17  <SOH> BACKGROUND <EOH>In a lithography system,...   \n",
      "18  <SOH> BACKGROUND ART <EOH>Liquid compositions ...   \n",
      "19  <SOH> BACKGROUND OF THE INVENTION <EOH>In rece...   \n",
      "\n",
      "                                              summary  \\\n",
      "0   <SOH> SUMMARY OF THE INVENTION <EOH>In all of ...   \n",
      "1   <SOH> SUMMARY OF THE INVENTION <EOH>According ...   \n",
      "2   <SOH> SUMMARY OF THE INVENTION <EOH>Accordingl...   \n",
      "3                                                 NaN   \n",
      "4   <SOH> BRIEF DESCRIPTION OF THE SEVERAL VIEWS O...   \n",
      "5   <SOH> SUMMARY OF THE INVENTION <EOH>In accorda...   \n",
      "6                <SOH> SUMMARY OF THE INVENTION <EOH>   \n",
      "7   <SOH> SUMMARY <EOH>However, some user inputs a...   \n",
      "8   <SOH> BACKGROUND AND SUMMARY <EOH>Conventional...   \n",
      "9   <SOH> SUMMARY OF THE INVENTION <EOH>It is an o...   \n",
      "10  <SOH> SUMMARY <EOH>This specification describe...   \n",
      "11  <SOH> SUMMARY OF THE INVENTION <EOH>This inven...   \n",
      "12  <SOH> SUMMARY <EOH>The present invention provi...   \n",
      "13  <SOH> SUMMARY <EOH>Embodiments of the present ...   \n",
      "14  <SOH> SUMMARY <EOH>Accordingly, the technical ...   \n",
      "15  <SOH> BRIEF DESCRIPTION OF THE DRAWINGS <EOH>S...   \n",
      "16  <SOH> SUMMARY OF THE INVENTION <EOH>In this co...   \n",
      "17  <SOH> SUMMARY OF THE INVENTION <EOH>According ...   \n",
      "18  <SOH> BRIEF DESCRIPTION OF THE DRAWINGS <EOH>F...   \n",
      "19  <SOH> SUMMARY OF THE INVENTION <EOH>Accordingl...   \n",
      "\n",
      "                                          description  ...  \\\n",
      "0   CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "1   BACKGROUND The invention relates to a foil rem...  ...   \n",
      "2   CROSS-REFERENCE TO RELATED APPLICATION(S) The ...  ...   \n",
      "3   CROSS-REFERENCE TO RELATED APPLICATION This ap...  ...   \n",
      "4   BACKGROUND OF THE INVENTION Millions of people...  ...   \n",
      "5   RELATED APPLICATION DATA The present applicati...  ...   \n",
      "6   TECHNICAL FIELD The present invention relates ...  ...   \n",
      "7   CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "8   CROSS-REFERENCE TO RELATED APPLICATION This ap...  ...   \n",
      "9   INCORPORATION BY REFERENCE The disclosure of J...  ...   \n",
      "10  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "11  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "12  CROSS REFERENCE TO RELATED APPLICATION(S) This...  ...   \n",
      "13  RELATED APPLICATIONS This application is a con...  ...   \n",
      "14  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "15  TECHNICAL FIELD The present disclosure relates...  ...   \n",
      "16  CROSS REFERENCE TO RELATED APPLICATION The pre...  ...   \n",
      "17  TECHNICAL FIELD The invention relates to an ap...  ...   \n",
      "18  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "19  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  ...   \n",
      "\n",
      "   small_entity_indicator aia_first_to_file  foreign  \\\n",
      "0            UNDISCOUNTED              true     True   \n",
      "1            UNDISCOUNTED              true     True   \n",
      "2            UNDISCOUNTED             false     True   \n",
      "3            UNDISCOUNTED              true     True   \n",
      "4            UNDISCOUNTED              true    False   \n",
      "5            UNDISCOUNTED             false    False   \n",
      "6            UNDISCOUNTED              true     True   \n",
      "7            UNDISCOUNTED             false     True   \n",
      "8            UNDISCOUNTED              true     True   \n",
      "9            UNDISCOUNTED              true     True   \n",
      "10           UNDISCOUNTED              true    False   \n",
      "11           UNDISCOUNTED              true    False   \n",
      "12           UNDISCOUNTED              true    False   \n",
      "13                  SMALL              true     True   \n",
      "14           UNDISCOUNTED             false     True   \n",
      "15           UNDISCOUNTED              true    False   \n",
      "16           UNDISCOUNTED             false     True   \n",
      "17                  SMALL              true    False   \n",
      "18           UNDISCOUNTED             false     True   \n",
      "19           UNDISCOUNTED              true    False   \n",
      "\n",
      "    small_entity_indicator_dict_value  aia_first_to_file_dict_value  \\\n",
      "0                                   1                             1   \n",
      "1                                   1                             1   \n",
      "2                                   1                             0   \n",
      "3                                   1                             1   \n",
      "4                                   1                             1   \n",
      "5                                   1                             0   \n",
      "6                                   1                             1   \n",
      "7                                   1                             0   \n",
      "8                                   1                             1   \n",
      "9                                   1                             1   \n",
      "10                                  1                             1   \n",
      "11                                  1                             1   \n",
      "12                                  1                             1   \n",
      "13                                  0                             1   \n",
      "14                                  1                             0   \n",
      "15                                  1                             1   \n",
      "16                                  1                             0   \n",
      "17                                  0                             1   \n",
      "18                                  1                             0   \n",
      "19                                  1                             1   \n",
      "\n",
      "   foreign_dict_value  ipc_label_value filing_month_value  \\\n",
      "0                   1             H04N                 08   \n",
      "1                   1             B65H                 09   \n",
      "2                   1             A01N                 08   \n",
      "3                   1             G11C                 08   \n",
      "4                   0             H04W                 09   \n",
      "5                   0             A61N                 08   \n",
      "6                   1             F16C                 08   \n",
      "7                   1             G06F                 07   \n",
      "8                   1             H04B                 09   \n",
      "9                   1             B60L                 09   \n",
      "10                  0             F28F                 08   \n",
      "11                  0             A61G                 09   \n",
      "12                  0             G01B                 08   \n",
      "13                  1             F16L                 07   \n",
      "14                  1             H04L                 08   \n",
      "15                  0             H04N                 07   \n",
      "16                  1             B41J                 09   \n",
      "17                  0             H01J                 07   \n",
      "18                  1             H01M                 08   \n",
      "19                  0             C07D                 09   \n",
      "\n",
      "   examiner_art_unit_value  output_onehot  \n",
      "0                      282         [0, 1]  \n",
      "1                       75         [0, 1]  \n",
      "2                       13         [1, 0]  \n",
      "3                      322         [1, 0]  \n",
      "4                      270         [0, 1]  \n",
      "5                      480         [0, 1]  \n",
      "6                      412         [1, 0]  \n",
      "7                      254         [0, 1]  \n",
      "8                      302         [0, 1]  \n",
      "9                      352         [1, 0]  \n",
      "10                      90         [0, 1]  \n",
      "11                      97         [1, 0]  \n",
      "12                     366         [0, 1]  \n",
      "13                     478         [1, 0]  \n",
      "14                     214         [1, 0]  \n",
      "15                     183         [0, 1]  \n",
      "16                     342         [0, 1]  \n",
      "17                     363         [1, 0]  \n",
      "18                      82         [0, 1]  \n",
      "19                      14         [1, 0]  \n",
      "\n",
      "[20 rows x 27 columns]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Convert this to many sentences within claims for training data\n",
    "claims_mod_list = []\n",
    "\n",
    "sentences_num_param = 31\n",
    "\n",
    "for i in range(len(train_df)):  \n",
    "  list_to_append = re.split(r'\\s+\\d+\\.\\s+', train_df.iloc[i][\"claims\"])\n",
    "  list_to_append[0] = list_to_append[0][3:]\n",
    "  \n",
    "  # injecting meta data here\n",
    "  list_to_append.append(train_df.iloc[i][\"small_entity_indicator_dict_value\"])  \n",
    "  list_to_append.append(train_df.iloc[i][\"aia_first_to_file_dict_value\"]) \n",
    "  list_to_append.append(train_df.iloc[i][\"foreign_dict_value\"])   \n",
    "  list_to_append.append(train_df.iloc[i][\"examiner_art_unit_value\"]) \n",
    "  list_to_append.append(train_df.iloc[i][\"ipc_label_value\"])\n",
    "  list_to_append.append(train_df.iloc[i][\"filing_month_value\"])\n",
    "\n",
    "  if(len(list_to_append) >= sentences_num_param):\n",
    "    list_to_append = list_to_append[:sentences_num_param] \n",
    "  else:\n",
    "    list_length = sentences_num_param - len(list_to_append)\n",
    "    while list_length > 0:\n",
    "      list_to_append.append(\"\")\n",
    "      list_length = list_length - 1\n",
    "    \n",
    "  claims_mod_list.append(list_to_append)\n",
    "  \n",
    "\n",
    "# insert claims_mod to train_df\n",
    "train_df.insert(0, \"claims_mod\", claims_mod_list)\n",
    "print(train_df.head(20))\n",
    "print(type(train_df[\"claims_mod\"][0]))\n",
    "\n",
    "\n",
    "# Convert this to many sentences within claims for validation data\n",
    "claims_mod_list = []\n",
    "\n",
    "for i in range(len(validation_df)):  \n",
    "  list_to_append = re.split(r'\\s+\\d+\\.\\s+', validation_df.iloc[i][\"claims\"])\n",
    "  list_to_append[0] = list_to_append[0][3:]\n",
    "    \n",
    "  # injecting meta data here\n",
    "  list_to_append.append(validation_df.iloc[i][\"small_entity_indicator_dict_value\"])  \n",
    "  list_to_append.append(validation_df.iloc[i][\"aia_first_to_file_dict_value\"]) \n",
    "  list_to_append.append(validation_df.iloc[i][\"foreign_dict_value\"])   \n",
    "  list_to_append.append(validation_df.iloc[i][\"examiner_art_unit_value\"])   \n",
    "  list_to_append.append(validation_df.iloc[i][\"ipc_label_value\"])\n",
    "  list_to_append.append(validation_df.iloc[i][\"filing_month_value\"])\n",
    "\n",
    "  if(len(list_to_append) >= sentences_num_param):\n",
    "    list_to_append = list_to_append[:sentences_num_param] # retain only the first 10 elements in the list\n",
    "  else:\n",
    "    list_length = sentences_num_param - len(list_to_append)\n",
    "    while list_length > 0:\n",
    "      list_to_append.append(\"\")\n",
    "      list_length = list_length - 1\n",
    "    \n",
    "  claims_mod_list.append(list_to_append)\n",
    "  \n",
    "\n",
    "# insert claims_mod to validation_df\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "validation_df.insert(0, \"claims_mod\", claims_mod_list)\n",
    "print(validation_df.head(20))\n",
    "print(type(validation_df[\"claims_mod\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYfyv6YTxcxs"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "class PatentLLM(nn.Module):   \n",
    "  def __init__(self, model_name, dim_model = 768, num_labels = 2, sentences_num = 15):       \n",
    "    super(PatentLLM, self).__init__()\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # Initiate the base model to be used\n",
    "    word_embedding_model = models.Transformer(model_name, max_seq_length = 512)\n",
    "    # Initiate the pooling method for the base model after processed (i.e. mean, max, etc.)\n",
    "    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode_max_tokens = False, pooling_mode_mean_tokens = False, pooling_mode_mean_sqrt_len_tokens = True)\n",
    "    # Initiate sentence transformer; change this to Scibert, Roberta, Bert, DistilBert, etc. in the modules piece\n",
    "    self.model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda') \n",
    "\n",
    "    # Transformer layers\n",
    "    self.encoder_layer1 = nn.TransformerEncoderLayer(d_model=dim_model, nhead=8)\n",
    "    self.encoder_layer2 = nn.TransformerEncoderLayer(d_model=dim_model, nhead=8)\n",
    "    self.encoder_layer3 = nn.TransformerEncoderLayer(d_model=dim_model, nhead=8)\n",
    "\n",
    "    # linear layer\n",
    "    self.linear_layer = nn.Linear(dim_model, dim_model)\n",
    "\n",
    "    # Dropout layer \n",
    "    self.dropout_layer = nn.Dropout(0.25)\n",
    "\n",
    "    # classification layer \n",
    "    self.classification_layer = nn.Linear(dim_model * sentences_num, num_labels)\n",
    "\n",
    "  def forward(self, batch_data):\n",
    "    tokenized_batch_data = []\n",
    "\n",
    "    # process data\n",
    "    for i in range(len(batch_data)):\n",
    "      result_ith = torch.tensor(self.model.encode(batch_data.iloc[i][\"claims_mod\"]))\n",
    "      tokenized_batch_data.append(result_ith)\n",
    "\n",
    "    # convert this into a tensor \n",
    "    result = torch.stack(tokenized_batch_data).to(device)\n",
    "\n",
    "    # pass thru transformer encoder layers\n",
    "    result = self.encoder_layer1(result)\n",
    "    result = self.encoder_layer2(result)\n",
    "    result = self.encoder_layer3(result)\n",
    "\n",
    "    # pass thru a linear layer \n",
    "    result = self.linear_layer(result)\n",
    "\n",
    "    # pass thru a dropout layer\n",
    "    result = self.dropout_layer(result)\n",
    "\n",
    "    # flatten the result\n",
    "    result = result.view(result.shape[0], -1)\n",
    "\n",
    "    # pass thru a classification layer -> (16 x 2)\n",
    "    logits = self.classification_layer(result)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad_n9eDmxfqd"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# SETTING BATCH_SIZE PARAM\n",
    "batch_size_param = 16\n",
    "\n",
    "def collate_fn(list_items):\n",
    "  x = []\n",
    "  y = []\n",
    "  for x_, y_ in list_items:\n",
    "      x.append(x_)\n",
    "      y.append(y_)\n",
    "  return x, y\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "  def __init__(self, train_df_data, validation_df_data):\n",
    "      self.x = train_df_data\n",
    "      self.y = validation_df_data\n",
    "  def __getitem__(self,index):\n",
    "      return self.x[index],self.y[index]\n",
    "  def __len__(self):\n",
    "      return len(self.x)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "h = torch.Generator()\n",
    "h.manual_seed(42)\n",
    "\n",
    "train_preload = CustomDataSet(train_df[\"claims_mod\"].tolist(), train_df[\"output_onehot\"].tolist())\n",
    "train_dataloader = DataLoader(train_preload, batch_size=batch_size_param, collate_fn=collate_fn, shuffle = True, generator = g)\n",
    "\n",
    "validation_preload = CustomDataSet(validation_df[\"claims_mod\"].tolist(), validation_df[\"output_onehot\"].tolist())\n",
    "validation_dataloader = DataLoader(validation_preload, batch_size=batch_size_param, collate_fn=collate_fn, shuffle = True, generator = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDB7dk7BxhW7"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "epochs = 20\n",
    "model = PatentLLM(\"allenai/scibert_scivocab_uncased\", sentences_num=sentences_num_param)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# Implement F1 Score\n",
    "def flat_accuracy(preds, labels):\n",
    "\n",
    "    pred_flat = torch.argmax(preds, dim=1).flatten()  \n",
    "    labels_flat = torch.argmax(labels, dim=1).flatten()  \n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    pred_flat_num = pred_flat.detach().cpu().numpy()\n",
    "    labels_flat_num = labels_flat.to('cpu').numpy()\n",
    "        \n",
    "    accuracy = np.sum(pred_flat_num == labels_flat_num) / len(labels_flat_num)\n",
    "    \n",
    "    # accuracy: 0\n",
    "    # pred_flat: 1\n",
    "    # labels_flat: 2\n",
    "    return_package = [accuracy, pred_flat_num, labels_flat_num]\n",
    "    \n",
    "    return return_package\n",
    "  \n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# Functions for saving and loading model parameters and metrics.\n",
    "def save_checkpoint(path, model, valid_loss):\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}, path)\n",
    "    \n",
    "def load_checkpoint(path, model):    \n",
    "    state_dict = torch.load(path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzUI8L8vxjTj",
    "outputId": "f619ca9a-0b66-4049-9025-d166b7b7bb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "\u001b[K     |████████████████████████████████| 512 kB 28.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
      "Installing collected packages: torchmetrics\n",
      "Successfully installed torchmetrics-0.11.0\n",
      "127098626\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6663)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.4998)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.9992)\n",
      "  Accuracy: 0.49960\n",
      "  Validation took: 0:07:33\n",
      "Initial Validation Accuracy level:  0.4996006389776358\n",
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:08:30.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:09:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:10:27.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:11:24.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:12:22.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:13:19.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:14:17.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:15:16.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:16:11.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:17:08.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:18:07.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:19:04.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:20:01.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:20:58.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:21:59.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:22:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:23:57.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:24:54.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:25:52.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:26:51.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:27:49.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:28:46.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:29:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:30:41.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:31:38.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:32:35.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:33:33.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:34:31.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:35:28.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:36:24.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:37:22.\n",
      "\n",
      "  Average training loss: 0.66476\n",
      "  Training epoch took: 0:37:36\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6340)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6210)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6476)\n",
      "  Accuracy: 0.62580\n",
      "  Validation took: 0:45:07\n",
      "Validation Accuracy level:  0.6257987220447284\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:46:18.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:47:14.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:48:12.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:49:09.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:50:07.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:51:04.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:52:04.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:53:00.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:53:59.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:54:56.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:55:53.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:56:50.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:57:48.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:58:46.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:59:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 1:00:41.\n",
      "  Batch   680  of  1,250.    Elapsed: 1:01:38.\n",
      "  Batch   720  of  1,250.    Elapsed: 1:02:37.\n",
      "  Batch   760  of  1,250.    Elapsed: 1:03:34.\n",
      "  Batch   800  of  1,250.    Elapsed: 1:04:29.\n",
      "  Batch   840  of  1,250.    Elapsed: 1:05:27.\n",
      "  Batch   880  of  1,250.    Elapsed: 1:06:25.\n",
      "  Batch   920  of  1,250.    Elapsed: 1:07:25.\n",
      "  Batch   960  of  1,250.    Elapsed: 1:08:22.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 1:09:19.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 1:10:16.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 1:11:14.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 1:12:12.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 1:13:11.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 1:14:08.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 1:15:05.\n",
      "\n",
      "  Average training loss: 0.63962\n",
      "  Training epoch took: 1:15:21\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6412)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6345)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6480)\n",
      "  Accuracy: 0.63738\n",
      "  Validation took: 1:22:51\n",
      "Validation Accuracy level:  0.6373801916932907\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 1:23:51.\n",
      "  Batch    80  of  1,250.    Elapsed: 1:24:48.\n",
      "  Batch   120  of  1,250.    Elapsed: 1:25:46.\n",
      "  Batch   160  of  1,250.    Elapsed: 1:26:44.\n",
      "  Batch   200  of  1,250.    Elapsed: 1:27:42.\n",
      "  Batch   240  of  1,250.    Elapsed: 1:28:40.\n",
      "  Batch   280  of  1,250.    Elapsed: 1:29:38.\n",
      "  Batch   320  of  1,250.    Elapsed: 1:30:38.\n",
      "  Batch   360  of  1,250.    Elapsed: 1:31:34.\n",
      "  Batch   400  of  1,250.    Elapsed: 1:32:32.\n",
      "  Batch   440  of  1,250.    Elapsed: 1:33:32.\n",
      "  Batch   480  of  1,250.    Elapsed: 1:34:29.\n",
      "  Batch   520  of  1,250.    Elapsed: 1:35:26.\n",
      "  Batch   560  of  1,250.    Elapsed: 1:36:23.\n",
      "  Batch   600  of  1,250.    Elapsed: 1:37:19.\n",
      "  Batch   640  of  1,250.    Elapsed: 1:38:18.\n",
      "  Batch   680  of  1,250.    Elapsed: 1:39:16.\n",
      "  Batch   720  of  1,250.    Elapsed: 1:40:13.\n",
      "  Batch   760  of  1,250.    Elapsed: 1:41:10.\n",
      "  Batch   800  of  1,250.    Elapsed: 1:42:06.\n",
      "  Batch   840  of  1,250.    Elapsed: 1:43:05.\n",
      "  Batch   880  of  1,250.    Elapsed: 1:44:04.\n",
      "  Batch   920  of  1,250.    Elapsed: 1:45:02.\n",
      "  Batch   960  of  1,250.    Elapsed: 1:46:00.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 1:46:59.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 1:47:55.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 1:48:52.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 1:49:48.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 1:50:44.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 1:51:43.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 1:52:41.\n",
      "\n",
      "  Average training loss: 0.62571\n",
      "  Training epoch took: 1:52:55\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6935)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.5864)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.8484)\n",
      "  Accuracy: 0.62540\n",
      "  Validation took: 2:00:26\n",
      "Validation Accuracy level:  0.6253993610223643\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 2:01:23.\n",
      "  Batch    80  of  1,250.    Elapsed: 2:02:22.\n",
      "  Batch   120  of  1,250.    Elapsed: 2:03:19.\n",
      "  Batch   160  of  1,250.    Elapsed: 2:04:19.\n",
      "  Batch   200  of  1,250.    Elapsed: 2:05:17.\n",
      "  Batch   240  of  1,250.    Elapsed: 2:06:15.\n",
      "  Batch   280  of  1,250.    Elapsed: 2:07:13.\n",
      "  Batch   320  of  1,250.    Elapsed: 2:08:11.\n",
      "  Batch   360  of  1,250.    Elapsed: 2:09:07.\n",
      "  Batch   400  of  1,250.    Elapsed: 2:10:02.\n",
      "  Batch   440  of  1,250.    Elapsed: 2:10:59.\n",
      "  Batch   480  of  1,250.    Elapsed: 2:11:57.\n",
      "  Batch   520  of  1,250.    Elapsed: 2:12:53.\n",
      "  Batch   560  of  1,250.    Elapsed: 2:13:52.\n",
      "  Batch   600  of  1,250.    Elapsed: 2:14:49.\n",
      "  Batch   640  of  1,250.    Elapsed: 2:15:48.\n",
      "  Batch   680  of  1,250.    Elapsed: 2:16:45.\n",
      "  Batch   720  of  1,250.    Elapsed: 2:17:42.\n",
      "  Batch   760  of  1,250.    Elapsed: 2:18:40.\n",
      "  Batch   800  of  1,250.    Elapsed: 2:19:38.\n",
      "  Batch   840  of  1,250.    Elapsed: 2:20:35.\n",
      "  Batch   880  of  1,250.    Elapsed: 2:21:34.\n",
      "  Batch   920  of  1,250.    Elapsed: 2:22:33.\n",
      "  Batch   960  of  1,250.    Elapsed: 2:23:29.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 2:24:28.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 2:25:25.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 2:26:20.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 2:27:20.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 2:28:19.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 2:29:18.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 2:30:16.\n",
      "\n",
      "  Average training loss: 0.61507\n",
      "  Training epoch took: 2:30:31\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6227)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6619)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5880)\n",
      "  Accuracy: 0.64337\n",
      "  Validation took: 2:38:02\n",
      "Validation Accuracy level:  0.643370607028754\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 2:39:05.\n",
      "  Batch    80  of  1,250.    Elapsed: 2:40:02.\n",
      "  Batch   120  of  1,250.    Elapsed: 2:40:58.\n",
      "  Batch   160  of  1,250.    Elapsed: 2:41:55.\n",
      "  Batch   200  of  1,250.    Elapsed: 2:42:53.\n",
      "  Batch   240  of  1,250.    Elapsed: 2:43:49.\n",
      "  Batch   280  of  1,250.    Elapsed: 2:44:49.\n",
      "  Batch   320  of  1,250.    Elapsed: 2:45:47.\n",
      "  Batch   360  of  1,250.    Elapsed: 2:46:44.\n",
      "  Batch   400  of  1,250.    Elapsed: 2:47:41.\n",
      "  Batch   440  of  1,250.    Elapsed: 2:48:38.\n",
      "  Batch   480  of  1,250.    Elapsed: 2:49:36.\n",
      "  Batch   520  of  1,250.    Elapsed: 2:50:34.\n",
      "  Batch   560  of  1,250.    Elapsed: 2:51:32.\n",
      "  Batch   600  of  1,250.    Elapsed: 2:52:30.\n",
      "  Batch   640  of  1,250.    Elapsed: 2:53:28.\n",
      "  Batch   680  of  1,250.    Elapsed: 2:54:28.\n",
      "  Batch   720  of  1,250.    Elapsed: 2:55:25.\n",
      "  Batch   760  of  1,250.    Elapsed: 2:56:23.\n",
      "  Batch   800  of  1,250.    Elapsed: 2:57:23.\n",
      "  Batch   840  of  1,250.    Elapsed: 2:58:20.\n",
      "  Batch   880  of  1,250.    Elapsed: 2:59:17.\n",
      "  Batch   920  of  1,250.    Elapsed: 3:00:15.\n",
      "  Batch   960  of  1,250.    Elapsed: 3:01:12.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 3:02:11.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 3:03:09.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 3:04:08.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 3:05:05.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 3:06:00.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 3:06:58.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 3:07:57.\n",
      "\n",
      "  Average training loss: 0.60302\n",
      "  Training epoch took: 3:08:12\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6762)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6236)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7384)\n",
      "  Accuracy: 0.64597\n",
      "  Validation took: 3:15:43\n",
      "Validation Accuracy level:  0.6459664536741214\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 3:16:42.\n",
      "  Batch    80  of  1,250.    Elapsed: 3:17:38.\n",
      "  Batch   120  of  1,250.    Elapsed: 3:18:39.\n",
      "  Batch   160  of  1,250.    Elapsed: 3:19:35.\n",
      "  Batch   200  of  1,250.    Elapsed: 3:20:32.\n",
      "  Batch   240  of  1,250.    Elapsed: 3:21:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 3:22:26.\n",
      "  Batch   320  of  1,250.    Elapsed: 3:23:25.\n",
      "  Batch   360  of  1,250.    Elapsed: 3:24:21.\n",
      "  Batch   400  of  1,250.    Elapsed: 3:25:19.\n",
      "  Batch   440  of  1,250.    Elapsed: 3:26:14.\n",
      "  Batch   480  of  1,250.    Elapsed: 3:27:13.\n",
      "  Batch   520  of  1,250.    Elapsed: 3:28:12.\n",
      "  Batch   560  of  1,250.    Elapsed: 3:29:09.\n",
      "  Batch   600  of  1,250.    Elapsed: 3:30:08.\n",
      "  Batch   640  of  1,250.    Elapsed: 3:31:06.\n",
      "  Batch   680  of  1,250.    Elapsed: 3:32:03.\n",
      "  Batch   720  of  1,250.    Elapsed: 3:33:01.\n",
      "  Batch   760  of  1,250.    Elapsed: 3:33:58.\n",
      "  Batch   800  of  1,250.    Elapsed: 3:34:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 3:35:57.\n",
      "  Batch   880  of  1,250.    Elapsed: 3:36:53.\n",
      "  Batch   920  of  1,250.    Elapsed: 3:37:51.\n",
      "  Batch   960  of  1,250.    Elapsed: 3:38:49.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 3:39:48.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 3:40:45.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 3:41:44.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 3:42:42.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 3:43:38.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 3:44:35.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 3:45:33.\n",
      "\n",
      "  Average training loss: 0.59078\n",
      "  Training epoch took: 3:45:47\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6627)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6409)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6860)\n",
      "  Accuracy: 0.65056\n",
      "  Validation took: 3:53:17\n",
      "Validation Accuracy level:  0.6505591054313099\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 3:54:12.\n",
      "  Batch    80  of  1,250.    Elapsed: 3:55:09.\n",
      "  Batch   120  of  1,250.    Elapsed: 3:56:07.\n",
      "  Batch   160  of  1,250.    Elapsed: 3:57:05.\n",
      "  Batch   200  of  1,250.    Elapsed: 3:58:03.\n",
      "  Batch   240  of  1,250.    Elapsed: 3:59:01.\n",
      "  Batch   280  of  1,250.    Elapsed: 3:59:59.\n",
      "  Batch   320  of  1,250.    Elapsed: 4:00:56.\n",
      "  Batch   360  of  1,250.    Elapsed: 4:01:54.\n",
      "  Batch   400  of  1,250.    Elapsed: 4:02:52.\n",
      "  Batch   440  of  1,250.    Elapsed: 4:03:50.\n",
      "  Batch   480  of  1,250.    Elapsed: 4:04:47.\n",
      "  Batch   520  of  1,250.    Elapsed: 4:05:44.\n",
      "  Batch   560  of  1,250.    Elapsed: 4:06:41.\n",
      "  Batch   600  of  1,250.    Elapsed: 4:07:39.\n",
      "  Batch   640  of  1,250.    Elapsed: 4:08:39.\n",
      "  Batch   680  of  1,250.    Elapsed: 4:09:38.\n",
      "  Batch   720  of  1,250.    Elapsed: 4:10:34.\n",
      "  Batch   760  of  1,250.    Elapsed: 4:11:32.\n",
      "  Batch   800  of  1,250.    Elapsed: 4:12:31.\n",
      "  Batch   840  of  1,250.    Elapsed: 4:13:29.\n",
      "  Batch   880  of  1,250.    Elapsed: 4:14:25.\n",
      "  Batch   920  of  1,250.    Elapsed: 4:15:24.\n",
      "  Batch   960  of  1,250.    Elapsed: 4:16:21.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 4:17:19.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 4:18:15.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 4:19:11.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 4:20:09.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 4:21:10.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 4:22:08.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 4:23:04.\n",
      "\n",
      "  Average training loss: 0.57446\n",
      "  Training epoch took: 4:23:19\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6677)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6239)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7180)\n",
      "  Accuracy: 0.64257\n",
      "  Validation took: 4:30:50\n",
      "Validation Accuracy level:  0.6425718849840255\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 4:31:46.\n",
      "  Batch    80  of  1,250.    Elapsed: 4:32:46.\n",
      "  Batch   120  of  1,250.    Elapsed: 4:33:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 4:34:42.\n",
      "  Batch   200  of  1,250.    Elapsed: 4:35:39.\n",
      "  Batch   240  of  1,250.    Elapsed: 4:36:36.\n",
      "  Batch   280  of  1,250.    Elapsed: 4:37:34.\n",
      "  Batch   320  of  1,250.    Elapsed: 4:38:31.\n",
      "  Batch   360  of  1,250.    Elapsed: 4:39:29.\n",
      "  Batch   400  of  1,250.    Elapsed: 4:40:25.\n",
      "  Batch   440  of  1,250.    Elapsed: 4:41:22.\n",
      "  Batch   480  of  1,250.    Elapsed: 4:42:19.\n",
      "  Batch   520  of  1,250.    Elapsed: 4:43:19.\n",
      "  Batch   560  of  1,250.    Elapsed: 4:44:16.\n",
      "  Batch   600  of  1,250.    Elapsed: 4:45:13.\n",
      "  Batch   640  of  1,250.    Elapsed: 4:46:12.\n",
      "  Batch   680  of  1,250.    Elapsed: 4:47:10.\n",
      "  Batch   720  of  1,250.    Elapsed: 4:48:06.\n",
      "  Batch   760  of  1,250.    Elapsed: 4:49:03.\n",
      "  Batch   800  of  1,250.    Elapsed: 4:50:00.\n",
      "  Batch   840  of  1,250.    Elapsed: 4:50:58.\n",
      "  Batch   880  of  1,250.    Elapsed: 4:51:55.\n",
      "  Batch   920  of  1,250.    Elapsed: 4:52:53.\n",
      "  Batch   960  of  1,250.    Elapsed: 4:53:51.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 4:54:48.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 4:55:46.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 4:56:44.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 4:57:43.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 4:58:41.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 4:59:39.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 5:00:38.\n",
      "\n",
      "  Average training loss: 0.55643\n",
      "  Training epoch took: 5:00:53\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6474)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6327)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6628)\n",
      "  Accuracy: 0.63918\n",
      "  Validation took: 5:08:23\n",
      "Validation Accuracy level:  0.6391773162939297\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 5:09:20.\n",
      "  Batch    80  of  1,250.    Elapsed: 5:10:19.\n",
      "  Batch   120  of  1,250.    Elapsed: 5:11:16.\n",
      "  Batch   160  of  1,250.    Elapsed: 5:12:13.\n",
      "  Batch   200  of  1,250.    Elapsed: 5:13:11.\n",
      "  Batch   240  of  1,250.    Elapsed: 5:14:08.\n",
      "  Batch   280  of  1,250.    Elapsed: 5:15:05.\n",
      "  Batch   320  of  1,250.    Elapsed: 5:16:02.\n",
      "  Batch   360  of  1,250.    Elapsed: 5:17:00.\n",
      "  Batch   400  of  1,250.    Elapsed: 5:17:58.\n",
      "  Batch   440  of  1,250.    Elapsed: 5:18:56.\n",
      "  Batch   480  of  1,250.    Elapsed: 5:19:51.\n",
      "  Batch   520  of  1,250.    Elapsed: 5:20:48.\n",
      "  Batch   560  of  1,250.    Elapsed: 5:21:47.\n",
      "  Batch   600  of  1,250.    Elapsed: 5:22:42.\n",
      "  Batch   640  of  1,250.    Elapsed: 5:23:39.\n",
      "  Batch   680  of  1,250.    Elapsed: 5:24:37.\n",
      "  Batch   720  of  1,250.    Elapsed: 5:25:38.\n",
      "  Batch   760  of  1,250.    Elapsed: 5:26:34.\n",
      "  Batch   800  of  1,250.    Elapsed: 5:27:34.\n",
      "  Batch   840  of  1,250.    Elapsed: 5:28:31.\n",
      "  Batch   880  of  1,250.    Elapsed: 5:29:29.\n",
      "  Batch   920  of  1,250.    Elapsed: 5:30:26.\n",
      "  Batch   960  of  1,250.    Elapsed: 5:31:25.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 5:32:24.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 5:33:22.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 5:34:20.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 5:35:18.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 5:36:16.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 5:37:14.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 5:38:12.\n",
      "\n",
      "  Average training loss: 0.53612\n",
      "  Training epoch took: 5:38:26\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6263)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6394)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6136)\n",
      "  Accuracy: 0.63379\n",
      "  Validation took: 5:45:57\n",
      "Validation Accuracy level:  0.6337859424920128\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 5:46:55.\n",
      "  Batch    80  of  1,250.    Elapsed: 5:47:51.\n",
      "  Batch   120  of  1,250.    Elapsed: 5:48:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 5:49:43.\n",
      "  Batch   200  of  1,250.    Elapsed: 5:50:41.\n",
      "  Batch   240  of  1,250.    Elapsed: 5:51:38.\n",
      "  Batch   280  of  1,250.    Elapsed: 5:52:36.\n",
      "  Batch   320  of  1,250.    Elapsed: 5:53:33.\n",
      "  Batch   360  of  1,250.    Elapsed: 5:54:31.\n",
      "  Batch   400  of  1,250.    Elapsed: 5:55:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 5:56:29.\n",
      "  Batch   480  of  1,250.    Elapsed: 5:57:29.\n",
      "  Batch   520  of  1,250.    Elapsed: 5:58:25.\n",
      "  Batch   560  of  1,250.    Elapsed: 5:59:23.\n",
      "  Batch   600  of  1,250.    Elapsed: 6:00:21.\n",
      "  Batch   640  of  1,250.    Elapsed: 6:01:19.\n",
      "  Batch   680  of  1,250.    Elapsed: 6:02:17.\n",
      "  Batch   720  of  1,250.    Elapsed: 6:03:16.\n",
      "  Batch   760  of  1,250.    Elapsed: 6:04:15.\n",
      "  Batch   800  of  1,250.    Elapsed: 6:05:13.\n",
      "  Batch   840  of  1,250.    Elapsed: 6:06:11.\n",
      "  Batch   880  of  1,250.    Elapsed: 6:07:09.\n",
      "  Batch   920  of  1,250.    Elapsed: 6:08:08.\n",
      "  Batch   960  of  1,250.    Elapsed: 6:09:07.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 6:10:04.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 6:11:03.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 6:12:01.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 6:12:58.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 6:13:55.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 6:14:51.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 6:15:48.\n",
      "\n",
      "  Average training loss: 0.51686\n",
      "  Training epoch took: 6:16:03\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6473)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6453)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6492)\n",
      "  Accuracy: 0.64637\n",
      "  Validation took: 6:23:34\n",
      "Validation Accuracy level:  0.6463658146964856\n",
      "\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 6:24:30.\n",
      "  Batch    80  of  1,250.    Elapsed: 6:25:26.\n",
      "  Batch   120  of  1,250.    Elapsed: 6:26:23.\n",
      "  Batch   160  of  1,250.    Elapsed: 6:27:23.\n",
      "  Batch   200  of  1,250.    Elapsed: 6:28:22.\n",
      "  Batch   240  of  1,250.    Elapsed: 6:29:20.\n",
      "  Batch   280  of  1,250.    Elapsed: 6:30:19.\n",
      "  Batch   320  of  1,250.    Elapsed: 6:31:16.\n",
      "  Batch   360  of  1,250.    Elapsed: 6:32:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 6:33:13.\n",
      "  Batch   440  of  1,250.    Elapsed: 6:34:12.\n",
      "  Batch   480  of  1,250.    Elapsed: 6:35:10.\n",
      "  Batch   520  of  1,250.    Elapsed: 6:36:08.\n",
      "  Batch   560  of  1,250.    Elapsed: 6:37:06.\n",
      "  Batch   600  of  1,250.    Elapsed: 6:38:02.\n",
      "  Batch   640  of  1,250.    Elapsed: 6:39:00.\n",
      "  Batch   680  of  1,250.    Elapsed: 6:39:57.\n",
      "  Batch   720  of  1,250.    Elapsed: 6:40:56.\n",
      "  Batch   760  of  1,250.    Elapsed: 6:41:55.\n",
      "  Batch   800  of  1,250.    Elapsed: 6:42:52.\n",
      "  Batch   840  of  1,250.    Elapsed: 6:43:50.\n",
      "  Batch   880  of  1,250.    Elapsed: 6:44:48.\n",
      "  Batch   920  of  1,250.    Elapsed: 6:45:46.\n",
      "  Batch   960  of  1,250.    Elapsed: 6:46:43.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 6:47:41.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 6:48:38.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 6:49:37.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 6:50:33.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 6:51:30.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 6:52:28.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 6:53:25.\n",
      "\n",
      "  Average training loss: 0.49878\n",
      "  Training epoch took: 6:53:40\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6564)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6265)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6892)\n",
      "  Accuracy: 0.63938\n",
      "  Validation took: 7:01:11\n",
      "Validation Accuracy level:  0.6393769968051118\n",
      "\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 7:02:10.\n",
      "  Batch    80  of  1,250.    Elapsed: 7:03:10.\n",
      "  Batch   120  of  1,250.    Elapsed: 7:04:07.\n",
      "  Batch   160  of  1,250.    Elapsed: 7:05:05.\n",
      "  Batch   200  of  1,250.    Elapsed: 7:06:03.\n",
      "  Batch   240  of  1,250.    Elapsed: 7:07:02.\n",
      "  Batch   280  of  1,250.    Elapsed: 7:07:57.\n",
      "  Batch   320  of  1,250.    Elapsed: 7:08:51.\n",
      "  Batch   360  of  1,250.    Elapsed: 7:09:49.\n",
      "  Batch   400  of  1,250.    Elapsed: 7:10:45.\n",
      "  Batch   440  of  1,250.    Elapsed: 7:11:41.\n",
      "  Batch   480  of  1,250.    Elapsed: 7:12:38.\n",
      "  Batch   520  of  1,250.    Elapsed: 7:13:36.\n",
      "  Batch   560  of  1,250.    Elapsed: 7:14:32.\n",
      "  Batch   600  of  1,250.    Elapsed: 7:15:30.\n",
      "  Batch   640  of  1,250.    Elapsed: 7:16:28.\n",
      "  Batch   680  of  1,250.    Elapsed: 7:17:26.\n",
      "  Batch   720  of  1,250.    Elapsed: 7:18:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 7:19:26.\n",
      "  Batch   800  of  1,250.    Elapsed: 7:20:23.\n",
      "  Batch   840  of  1,250.    Elapsed: 7:21:20.\n",
      "  Batch   880  of  1,250.    Elapsed: 7:22:18.\n",
      "  Batch   920  of  1,250.    Elapsed: 7:23:16.\n",
      "  Batch   960  of  1,250.    Elapsed: 7:24:13.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 7:25:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 7:26:11.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 7:27:11.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 7:28:09.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 7:29:08.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 7:30:03.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 7:31:02.\n",
      "\n",
      "  Average training loss: 0.47611\n",
      "  Training epoch took: 7:31:17\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6576)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6298)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6880)\n",
      "  Accuracy: 0.64197\n",
      "  Validation took: 7:38:48\n",
      "Validation Accuracy level:  0.6419728434504792\n",
      "\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 7:39:44.\n",
      "  Batch    80  of  1,250.    Elapsed: 7:40:43.\n",
      "  Batch   120  of  1,250.    Elapsed: 7:41:40.\n",
      "  Batch   160  of  1,250.    Elapsed: 7:42:38.\n",
      "  Batch   200  of  1,250.    Elapsed: 7:43:35.\n",
      "  Batch   240  of  1,250.    Elapsed: 7:44:33.\n",
      "  Batch   280  of  1,250.    Elapsed: 7:45:31.\n",
      "  Batch   320  of  1,250.    Elapsed: 7:46:27.\n",
      "  Batch   360  of  1,250.    Elapsed: 7:47:26.\n",
      "  Batch   400  of  1,250.    Elapsed: 7:48:24.\n",
      "  Batch   440  of  1,250.    Elapsed: 7:49:21.\n",
      "  Batch   480  of  1,250.    Elapsed: 7:50:17.\n",
      "  Batch   520  of  1,250.    Elapsed: 7:51:16.\n",
      "  Batch   560  of  1,250.    Elapsed: 7:52:13.\n",
      "  Batch   600  of  1,250.    Elapsed: 7:53:12.\n",
      "  Batch   640  of  1,250.    Elapsed: 7:54:09.\n",
      "  Batch   680  of  1,250.    Elapsed: 7:55:09.\n",
      "  Batch   720  of  1,250.    Elapsed: 7:56:05.\n",
      "  Batch   760  of  1,250.    Elapsed: 7:57:01.\n",
      "  Batch   800  of  1,250.    Elapsed: 7:58:00.\n",
      "  Batch   840  of  1,250.    Elapsed: 7:58:59.\n",
      "  Batch   880  of  1,250.    Elapsed: 7:59:56.\n",
      "  Batch   920  of  1,250.    Elapsed: 8:00:54.\n",
      "  Batch   960  of  1,250.    Elapsed: 8:01:51.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 8:02:47.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 8:03:46.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 8:04:44.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 8:05:43.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 8:06:40.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 8:07:40.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 8:08:41.\n",
      "\n",
      "  Average training loss: 0.45417\n",
      "  Training epoch took: 8:08:54\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6581)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6181)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7036)\n",
      "  Accuracy: 0.63458\n",
      "  Validation took: 8:16:26\n",
      "Validation Accuracy level:  0.6345846645367412\n",
      "\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 8:17:25.\n",
      "  Batch    80  of  1,250.    Elapsed: 8:18:23.\n",
      "  Batch   120  of  1,250.    Elapsed: 8:19:24.\n",
      "  Batch   160  of  1,250.    Elapsed: 8:20:21.\n",
      "  Batch   200  of  1,250.    Elapsed: 8:21:17.\n",
      "  Batch   240  of  1,250.    Elapsed: 8:22:14.\n",
      "  Batch   280  of  1,250.    Elapsed: 8:23:12.\n",
      "  Batch   320  of  1,250.    Elapsed: 8:24:11.\n",
      "  Batch   360  of  1,250.    Elapsed: 8:25:09.\n",
      "  Batch   400  of  1,250.    Elapsed: 8:26:07.\n",
      "  Batch   440  of  1,250.    Elapsed: 8:27:01.\n",
      "  Batch   480  of  1,250.    Elapsed: 8:28:00.\n",
      "  Batch   520  of  1,250.    Elapsed: 8:28:56.\n",
      "  Batch   560  of  1,250.    Elapsed: 8:29:54.\n",
      "  Batch   600  of  1,250.    Elapsed: 8:30:50.\n",
      "  Batch   640  of  1,250.    Elapsed: 8:31:46.\n",
      "  Batch   680  of  1,250.    Elapsed: 8:32:45.\n",
      "  Batch   720  of  1,250.    Elapsed: 8:33:42.\n",
      "  Batch   760  of  1,250.    Elapsed: 8:34:41.\n",
      "  Batch   800  of  1,250.    Elapsed: 8:35:38.\n",
      "  Batch   840  of  1,250.    Elapsed: 8:36:35.\n",
      "  Batch   880  of  1,250.    Elapsed: 8:37:33.\n",
      "  Batch   920  of  1,250.    Elapsed: 8:38:31.\n",
      "  Batch   960  of  1,250.    Elapsed: 8:39:30.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 8:40:29.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 8:41:28.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 8:42:24.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 8:43:21.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 8:44:19.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 8:45:16.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 8:46:17.\n",
      "\n",
      "  Average training loss: 0.43188\n",
      "  Training epoch took: 8:46:32\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6665)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6080)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7376)\n",
      "  Accuracy: 0.63119\n",
      "  Validation took: 8:54:03\n",
      "Validation Accuracy level:  0.6311900958466453\n",
      "\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 8:55:03.\n",
      "  Batch    80  of  1,250.    Elapsed: 8:56:02.\n",
      "  Batch   120  of  1,250.    Elapsed: 8:57:00.\n",
      "  Batch   160  of  1,250.    Elapsed: 8:57:58.\n",
      "  Batch   200  of  1,250.    Elapsed: 8:58:56.\n",
      "  Batch   240  of  1,250.    Elapsed: 8:59:55.\n",
      "  Batch   280  of  1,250.    Elapsed: 9:00:54.\n",
      "  Batch   320  of  1,250.    Elapsed: 9:01:51.\n",
      "  Batch   360  of  1,250.    Elapsed: 9:02:51.\n",
      "  Batch   400  of  1,250.    Elapsed: 9:03:48.\n",
      "  Batch   440  of  1,250.    Elapsed: 9:04:45.\n",
      "  Batch   480  of  1,250.    Elapsed: 9:05:42.\n",
      "  Batch   520  of  1,250.    Elapsed: 9:06:41.\n",
      "  Batch   560  of  1,250.    Elapsed: 9:07:37.\n",
      "  Batch   600  of  1,250.    Elapsed: 9:08:32.\n",
      "  Batch   640  of  1,250.    Elapsed: 9:09:29.\n",
      "  Batch   680  of  1,250.    Elapsed: 9:10:28.\n",
      "  Batch   720  of  1,250.    Elapsed: 9:11:25.\n",
      "  Batch   760  of  1,250.    Elapsed: 9:12:24.\n",
      "  Batch   800  of  1,250.    Elapsed: 9:13:22.\n",
      "  Batch   840  of  1,250.    Elapsed: 9:14:21.\n",
      "  Batch   880  of  1,250.    Elapsed: 9:15:19.\n",
      "  Batch   920  of  1,250.    Elapsed: 9:16:16.\n",
      "  Batch   960  of  1,250.    Elapsed: 9:17:13.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 9:18:10.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 9:19:07.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 9:20:05.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 9:21:02.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 9:21:59.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 9:22:56.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 9:23:54.\n",
      "\n",
      "  Average training loss: 0.41248\n",
      "  Training epoch took: 9:24:08\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6665)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6019)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7468)\n",
      "  Accuracy: 0.62640\n",
      "  Validation took: 9:31:39\n",
      "Validation Accuracy level:  0.6263977635782748\n",
      "\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 9:32:37.\n",
      "  Batch    80  of  1,250.    Elapsed: 9:33:34.\n",
      "  Batch   120  of  1,250.    Elapsed: 9:34:32.\n",
      "  Batch   160  of  1,250.    Elapsed: 9:35:31.\n",
      "  Batch   200  of  1,250.    Elapsed: 9:36:28.\n",
      "  Batch   240  of  1,250.    Elapsed: 9:37:25.\n",
      "  Batch   280  of  1,250.    Elapsed: 9:38:22.\n",
      "  Batch   320  of  1,250.    Elapsed: 9:39:21.\n",
      "  Batch   360  of  1,250.    Elapsed: 9:40:19.\n",
      "  Batch   400  of  1,250.    Elapsed: 9:41:15.\n",
      "  Batch   440  of  1,250.    Elapsed: 9:42:13.\n",
      "  Batch   480  of  1,250.    Elapsed: 9:43:09.\n",
      "  Batch   520  of  1,250.    Elapsed: 9:44:06.\n",
      "  Batch   560  of  1,250.    Elapsed: 9:45:05.\n",
      "  Batch   600  of  1,250.    Elapsed: 9:46:02.\n",
      "  Batch   640  of  1,250.    Elapsed: 9:46:59.\n",
      "  Batch   680  of  1,250.    Elapsed: 9:47:57.\n",
      "  Batch   720  of  1,250.    Elapsed: 9:48:54.\n",
      "  Batch   760  of  1,250.    Elapsed: 9:49:51.\n",
      "  Batch   800  of  1,250.    Elapsed: 9:50:47.\n",
      "  Batch   840  of  1,250.    Elapsed: 9:51:46.\n",
      "  Batch   880  of  1,250.    Elapsed: 9:52:45.\n",
      "  Batch   920  of  1,250.    Elapsed: 9:53:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 9:54:42.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 9:55:40.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 9:56:40.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 9:57:39.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 9:58:38.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 9:59:36.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 10:00:34.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 10:01:31.\n",
      "\n",
      "  Average training loss: 0.39447\n",
      "  Training epoch took: 10:01:45\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6621)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6073)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7276)\n",
      "  Accuracy: 0.62899\n",
      "  Validation took: 10:09:17\n",
      "Validation Accuracy level:  0.6289936102236422\n",
      "\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 10:10:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 10:11:14.\n",
      "  Batch   120  of  1,250.    Elapsed: 10:12:13.\n",
      "  Batch   160  of  1,250.    Elapsed: 10:13:10.\n",
      "  Batch   200  of  1,250.    Elapsed: 10:14:08.\n",
      "  Batch   240  of  1,250.    Elapsed: 10:15:06.\n",
      "  Batch   280  of  1,250.    Elapsed: 10:16:06.\n",
      "  Batch   320  of  1,250.    Elapsed: 10:17:06.\n",
      "  Batch   360  of  1,250.    Elapsed: 10:18:04.\n",
      "  Batch   400  of  1,250.    Elapsed: 10:19:01.\n",
      "  Batch   440  of  1,250.    Elapsed: 10:20:00.\n",
      "  Batch   480  of  1,250.    Elapsed: 10:20:57.\n",
      "  Batch   520  of  1,250.    Elapsed: 10:21:56.\n",
      "  Batch   560  of  1,250.    Elapsed: 10:22:54.\n",
      "  Batch   600  of  1,250.    Elapsed: 10:23:49.\n",
      "  Batch   640  of  1,250.    Elapsed: 10:24:47.\n",
      "  Batch   680  of  1,250.    Elapsed: 10:25:44.\n",
      "  Batch   720  of  1,250.    Elapsed: 10:26:40.\n",
      "  Batch   760  of  1,250.    Elapsed: 10:27:38.\n",
      "  Batch   800  of  1,250.    Elapsed: 10:28:37.\n",
      "  Batch   840  of  1,250.    Elapsed: 10:29:34.\n",
      "  Batch   880  of  1,250.    Elapsed: 10:30:33.\n",
      "  Batch   920  of  1,250.    Elapsed: 10:31:31.\n",
      "  Batch   960  of  1,250.    Elapsed: 10:32:25.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 10:33:24.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 10:34:22.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 10:35:20.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 10:36:15.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 10:37:15.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 10:38:11.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 10:39:09.\n",
      "\n",
      "  Average training loss: 0.38208\n",
      "  Training epoch took: 10:39:25\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6566)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6106)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7100)\n",
      "  Accuracy: 0.62839\n",
      "  Validation took: 10:46:56\n",
      "Validation Accuracy level:  0.6283945686900958\n",
      "\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 10:47:56.\n",
      "  Batch    80  of  1,250.    Elapsed: 10:48:53.\n",
      "  Batch   120  of  1,250.    Elapsed: 10:49:49.\n",
      "  Batch   160  of  1,250.    Elapsed: 10:50:47.\n",
      "  Batch   200  of  1,250.    Elapsed: 10:51:42.\n",
      "  Batch   240  of  1,250.    Elapsed: 10:52:41.\n",
      "  Batch   280  of  1,250.    Elapsed: 10:53:39.\n",
      "  Batch   320  of  1,250.    Elapsed: 10:54:36.\n",
      "  Batch   360  of  1,250.    Elapsed: 10:55:33.\n",
      "  Batch   400  of  1,250.    Elapsed: 10:56:31.\n",
      "  Batch   440  of  1,250.    Elapsed: 10:57:29.\n",
      "  Batch   480  of  1,250.    Elapsed: 10:58:26.\n",
      "  Batch   520  of  1,250.    Elapsed: 10:59:25.\n",
      "  Batch   560  of  1,250.    Elapsed: 11:00:21.\n",
      "  Batch   600  of  1,250.    Elapsed: 11:01:18.\n",
      "  Batch   640  of  1,250.    Elapsed: 11:02:16.\n",
      "  Batch   680  of  1,250.    Elapsed: 11:03:15.\n",
      "  Batch   720  of  1,250.    Elapsed: 11:04:13.\n",
      "  Batch   760  of  1,250.    Elapsed: 11:05:10.\n",
      "  Batch   800  of  1,250.    Elapsed: 11:06:09.\n",
      "  Batch   840  of  1,250.    Elapsed: 11:07:07.\n",
      "  Batch   880  of  1,250.    Elapsed: 11:08:06.\n",
      "  Batch   920  of  1,250.    Elapsed: 11:09:03.\n",
      "  Batch   960  of  1,250.    Elapsed: 11:10:02.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 11:11:00.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 11:11:57.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 11:12:54.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 11:13:51.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 11:14:48.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 11:15:47.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 11:16:46.\n",
      "\n",
      "  Average training loss: 0.36512\n",
      "  Training epoch took: 11:17:00\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6531)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6084)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7048)\n",
      "  Accuracy: 0.62580\n",
      "  Validation took: 11:24:31\n",
      "Validation Accuracy level:  0.6257987220447284\n",
      "\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 11:25:26.\n",
      "  Batch    80  of  1,250.    Elapsed: 11:26:25.\n",
      "  Batch   120  of  1,250.    Elapsed: 11:27:22.\n",
      "  Batch   160  of  1,250.    Elapsed: 11:28:19.\n",
      "  Batch   200  of  1,250.    Elapsed: 11:29:19.\n",
      "  Batch   240  of  1,250.    Elapsed: 11:30:18.\n",
      "  Batch   280  of  1,250.    Elapsed: 11:31:15.\n",
      "  Batch   320  of  1,250.    Elapsed: 11:32:12.\n",
      "  Batch   360  of  1,250.    Elapsed: 11:33:10.\n",
      "  Batch   400  of  1,250.    Elapsed: 11:34:08.\n",
      "  Batch   440  of  1,250.    Elapsed: 11:35:06.\n",
      "  Batch   480  of  1,250.    Elapsed: 11:36:02.\n",
      "  Batch   520  of  1,250.    Elapsed: 11:37:01.\n",
      "  Batch   560  of  1,250.    Elapsed: 11:37:57.\n",
      "  Batch   600  of  1,250.    Elapsed: 11:38:54.\n",
      "  Batch   640  of  1,250.    Elapsed: 11:39:52.\n",
      "  Batch   680  of  1,250.    Elapsed: 11:40:50.\n",
      "  Batch   720  of  1,250.    Elapsed: 11:41:47.\n",
      "  Batch   760  of  1,250.    Elapsed: 11:42:46.\n",
      "  Batch   800  of  1,250.    Elapsed: 11:43:41.\n",
      "  Batch   840  of  1,250.    Elapsed: 11:44:40.\n",
      "  Batch   880  of  1,250.    Elapsed: 11:45:41.\n",
      "  Batch   920  of  1,250.    Elapsed: 11:46:39.\n",
      "  Batch   960  of  1,250.    Elapsed: 11:47:36.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 11:48:34.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 11:49:32.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 11:50:32.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 11:51:30.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 11:52:28.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 11:53:26.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 11:54:23.\n",
      "\n",
      "  Average training loss: 0.35485\n",
      "  Training epoch took: 11:54:37\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6589)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6149)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7096)\n",
      "  Accuracy: 0.63259\n",
      "  Validation took: 12:02:08\n",
      "Validation Accuracy level:  0.6325878594249201\n",
      "\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 12:03:05.\n",
      "  Batch    80  of  1,250.    Elapsed: 12:04:03.\n",
      "  Batch   120  of  1,250.    Elapsed: 12:05:01.\n",
      "  Batch   160  of  1,250.    Elapsed: 12:05:59.\n",
      "  Batch   200  of  1,250.    Elapsed: 12:06:55.\n",
      "  Batch   240  of  1,250.    Elapsed: 12:07:53.\n",
      "  Batch   280  of  1,250.    Elapsed: 12:08:50.\n",
      "  Batch   320  of  1,250.    Elapsed: 12:09:46.\n",
      "  Batch   360  of  1,250.    Elapsed: 12:10:45.\n",
      "  Batch   400  of  1,250.    Elapsed: 12:11:41.\n",
      "  Batch   440  of  1,250.    Elapsed: 12:12:39.\n",
      "  Batch   480  of  1,250.    Elapsed: 12:13:37.\n",
      "  Batch   520  of  1,250.    Elapsed: 12:14:35.\n",
      "  Batch   560  of  1,250.    Elapsed: 12:15:35.\n",
      "  Batch   600  of  1,250.    Elapsed: 12:16:34.\n",
      "  Batch   640  of  1,250.    Elapsed: 12:17:33.\n",
      "  Batch   680  of  1,250.    Elapsed: 12:18:30.\n",
      "  Batch   720  of  1,250.    Elapsed: 12:19:27.\n",
      "  Batch   760  of  1,250.    Elapsed: 12:20:24.\n",
      "  Batch   800  of  1,250.    Elapsed: 12:21:23.\n",
      "  Batch   840  of  1,250.    Elapsed: 12:22:21.\n",
      "  Batch   880  of  1,250.    Elapsed: 12:23:20.\n",
      "  Batch   920  of  1,250.    Elapsed: 12:24:19.\n",
      "  Batch   960  of  1,250.    Elapsed: 12:25:17.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 12:26:15.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 12:27:12.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 12:28:08.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 12:29:05.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 12:30:01.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 12:31:00.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 12:31:59.\n",
      "\n",
      "  Average training loss: 0.34631\n",
      "  Training epoch took: 12:32:13\n",
      "\n",
      "Running Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6606)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6126)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.7168)\n",
      "  Accuracy: 0.63179\n",
      "  Validation took: 12:39:44\n",
      "Validation Accuracy level:  0.6317891373801917\n"
     ]
    }
   ],
   "source": [
    "# Resources: https://colab.research.google.com/drive/1b0tRPNXHEFReOP5xY4eIWsl8G-Dma7ZN#scrollTo=uDLZmEC_oKo3\n",
    "\n",
    "!pip install torchmetrics\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall\n",
    "\n",
    "model.cuda()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Check parameters count\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))\n",
    "\n",
    "best_valid_loss = 1000\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "  target_list = []\n",
    "  output_list = []\n",
    "\n",
    "  if(epoch_i == 0):\n",
    "        \n",
    "    # Initial Validation\n",
    "    \n",
    "    print(\"Running Initial Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    eval_accuracy = 0\n",
    "    eval_step = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Initial Validation so no grad here\n",
    "    with torch.no_grad():\n",
    "      for step, batch in enumerate(validation_dataloader):       \n",
    "              \n",
    "        # convert to dataframe\n",
    "        validation_df_inputs_mod = pd.DataFrame({'claims_mod': batch[0]})\n",
    "        # convert to dataframe\n",
    "        validation_df_labels_mod = pd.DataFrame({'labels': batch[1]})\n",
    "        # join the two dataframes\n",
    "        validation_df_combined = pd.concat([validation_df_inputs_mod, validation_df_labels_mod], axis=1)        \n",
    "        \n",
    "        # get the logits ex. (16 samples x 2 neurons)\n",
    "        logits = model(validation_df_combined)\n",
    "       \n",
    "        # calculate the loss\n",
    "        loss_func = BCEWithLogitsLoss() \n",
    "\n",
    "        # reconvert validation_df_labels_mod into num_label columns        \n",
    "        validation_df_labels_mod[['REJECTED','ACCEPTED']] = pd.DataFrame(validation_df_labels_mod.labels.tolist(), index=validation_df_labels_mod.index)        \n",
    "        validation_df_labels_mod = validation_df_labels_mod.drop('labels', axis=1)\n",
    "        \n",
    "        label_tensor = torch.from_numpy(validation_df_labels_mod.to_numpy().astype(np.float32)).to(device)\n",
    "\n",
    "        return_values = flat_accuracy(logits, label_tensor)                \n",
    "        \n",
    "        eval_accuracy += return_values[0]\n",
    "        output_list.append(return_values[1]) \n",
    "        target_list.append(return_values[2])  \n",
    "        \n",
    "        eval_step = eval_step + 1\n",
    "        \n",
    "      outputs_concat = torch.tensor(np.concatenate(output_list))  \n",
    "      targets_concat = torch.tensor(np.concatenate(target_list))\n",
    "        \n",
    "      metric = BinaryF1Score()\n",
    "      print(\">>>>>>>>>>> F1 Score: \", metric(outputs_concat, targets_concat))\n",
    "\n",
    "      metric1 = BinaryPrecision()\n",
    "      print(\">>>>>>>>>>> Precision Score:\", metric1(outputs_concat, targets_concat))\n",
    "\n",
    "      metric2 = BinaryRecall()\n",
    "      print(\">>>>>>>>>>> Recall Score: \", metric2(outputs_concat, targets_concat))\n",
    "\n",
    "      # Report the final accuracy for this validation run.\n",
    "      print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/eval_step))\n",
    "      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "      # Reset target output list to none again\n",
    "      target_list = []\n",
    "      output_list = []\n",
    "      outputs_concat = None\n",
    "      targets_concat = None\n",
    "          \n",
    "      print(\"Initial Validation Accuracy level: \", (eval_accuracy / eval_step))\n",
    "    \n",
    "\n",
    "  # Training\n",
    "\n",
    "  print(\"\")\n",
    "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "  print('Training...')\n",
    "\n",
    "  total_loss = 0\n",
    "  total_val_loss = 0\n",
    "  model.train()\n",
    "\n",
    "  # measure total loss\n",
    "  total_loss = 0 \n",
    "\n",
    "  for step, batch in enumerate(train_dataloader):      \n",
    "\n",
    "    # Progress update every 40 batches.\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)    \n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "    # convert to dataframe\n",
    "    validation_df_inputs_mod = pd.DataFrame({'claims_mod': batch[0]})\n",
    "    # convert to dataframe\n",
    "    validation_df_labels_mod = pd.DataFrame({'labels': batch[1]})\n",
    "    # join the two dataframes\n",
    "    validation_df_combined = pd.concat([validation_df_inputs_mod, validation_df_labels_mod], axis=1)        \n",
    "\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # get the logits ex. (16 samples x 2 neurons)\n",
    "    logits = model(validation_df_combined)\n",
    "    \n",
    "    # calculate the loss\n",
    "    loss_func = BCEWithLogitsLoss()  \n",
    "\n",
    "    # reconvert validation_df_labels_mod into num_label columns        \n",
    "    validation_df_labels_mod[['REJECTED','ACCEPTED']] = pd.DataFrame(validation_df_labels_mod.labels.tolist(), index=validation_df_labels_mod.index)        \n",
    "    validation_df_labels_mod = validation_df_labels_mod.drop('labels', axis=1)\n",
    "\n",
    "    label_tensor = torch.from_numpy(validation_df_labels_mod.to_numpy().astype(np.float32)).to(device)    \n",
    "\n",
    "    loss = loss_func(logits,label_tensor) \n",
    "\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip the norm of the gradients to 1.0.\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "  # Calculate the average loss over the training data.\n",
    "  avg_train_loss = total_loss / len(train_dataloader)    \n",
    "  \n",
    "  print(\"\")\n",
    "  print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "  print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "  \n",
    "  # Validation\n",
    "\n",
    "  print(\"\\nRunning Validation...\")\n",
    "  eval_accuracy = 0\n",
    "  eval_step = 0\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  # Make sure no grad is here\n",
    "  with torch.no_grad():\n",
    "    for step, batch in enumerate(validation_dataloader):       \n",
    "            \n",
    "      # convert to dataframe\n",
    "      validation_df_inputs_mod = pd.DataFrame({'claims_mod': batch[0]})\n",
    "      # convert to dataframe\n",
    "      validation_df_labels_mod = pd.DataFrame({'labels': batch[1]})\n",
    "      # join the two dataframes\n",
    "      validation_df_combined = pd.concat([validation_df_inputs_mod, validation_df_labels_mod], axis=1)        \n",
    "      \n",
    "      # get the logits ex. (16 samples x 2 neurons)\n",
    "      logits = model(validation_df_combined)\n",
    "    \n",
    "      # calculate the loss\n",
    "      loss_func = BCEWithLogitsLoss()     \n",
    "\n",
    "      # reconvert validation_df_labels_mod into num_label columns        \n",
    "      validation_df_labels_mod[['REJECTED','ACCEPTED']] = pd.DataFrame(validation_df_labels_mod.labels.tolist(), index=validation_df_labels_mod.index)        \n",
    "      validation_df_labels_mod = validation_df_labels_mod.drop('labels', axis=1)\n",
    "      \n",
    "      label_tensor = torch.from_numpy(validation_df_labels_mod.to_numpy().astype(np.float32)).to(device)\n",
    "          \n",
    "      loss = loss_func(logits,label_tensor) # convert labels to float for calculation\n",
    "      total_val_loss = total_val_loss + loss.item()\n",
    "\n",
    "      return_values = flat_accuracy(logits, label_tensor)\n",
    "        \n",
    "      eval_accuracy += return_values[0]\n",
    "      output_list.append(return_values[1]) \n",
    "      target_list.append(return_values[2])  \n",
    "        \n",
    "      eval_step = eval_step + 1\n",
    "        \n",
    "    outputs_concat = torch.tensor(np.concatenate(output_list))  \n",
    "    targets_concat = torch.tensor(np.concatenate(target_list))\n",
    "\n",
    "    metric = BinaryF1Score()\n",
    "    print(\">>>>>>>>>>> F1 Score: \", metric(outputs_concat, targets_concat))\n",
    "\n",
    "    metric1 = BinaryPrecision()\n",
    "    print(\">>>>>>>>>>> Precision Score:\", metric1(outputs_concat, targets_concat))\n",
    "\n",
    "    metric2 = BinaryRecall()\n",
    "    print(\">>>>>>>>>>> Recall Score: \", metric2(outputs_concat, targets_concat))\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/eval_step))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # Reset target output list to none again\n",
    "    target_list = []\n",
    "    output_list = []\n",
    "    outputs_concat = None\n",
    "    targets_concat = None\n",
    " \n",
    "  # Calculate the average loss over the validation data.\n",
    "  avg_val_loss = total_val_loss / len(validation_dataloader) \n",
    "  # checkpoint\n",
    "  if best_valid_loss > avg_val_loss:\n",
    "    best_valid_loss = avg_val_loss\n",
    "    save_checkpoint('model.pkl', model, best_valid_loss)\n",
    "\n",
    "  print(\"Validation Accuracy level: \", (eval_accuracy / eval_step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "JzmQKhpFvLg3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "def evaluate(model, validation_dataloader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for step, batch in enumerate(validation_dataloader):       \n",
    "            \n",
    "        # convert to dataframe\n",
    "        validation_df_inputs_mod = pd.DataFrame({'claims_mod': batch[0]})\n",
    "        # convert to dataframe\n",
    "        validation_df_labels_mod = pd.DataFrame({'labels': batch[1]})\n",
    "        # join the two dataframes\n",
    "        validation_df_combined = pd.concat([validation_df_inputs_mod, validation_df_labels_mod], axis=1)        \n",
    "        \n",
    "        # get the logits ex. (16 samples x 2 neurons)\n",
    "        logits = model(validation_df_combined)\n",
    "\n",
    "        # reconvert validation_df_labels_mod into num_label columns        \n",
    "        validation_df_labels_mod[['REJECTED','ACCEPTED']] = pd.DataFrame(validation_df_labels_mod.labels.tolist(), index=validation_df_labels_mod.index)        \n",
    "        validation_df_labels_mod = validation_df_labels_mod.drop('labels', axis=1)\n",
    "        \n",
    "        # print(validation_df_labels_mod.head())\n",
    "        label_tensor = torch.from_numpy(validation_df_labels_mod.to_numpy().astype(np.float32)).to(device)\n",
    "        y_pred += torch.argmax(logits, dim=1).flatten()  \n",
    "        y_true += torch.argmax(label_tensor, dim=1).flatten()\n",
    "        \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=range(2), digits=4))\n",
    "\n",
    "    plt.figure(figsize=(15, 15))    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(2))\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.xaxis.set_ticklabels(range(2))\n",
    "    ax.yaxis.set_ticklabels(range(2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

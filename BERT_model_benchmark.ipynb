{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvTuLiRzoAwV",
    "outputId": "ca10daa5-2af2-4320-d51a-fe03194a167f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "# Reference: \n",
    "# 1. https://colab.research.google.com/drive/1wm8Z0ui8ZGSXoR50x52GvWMQkfSPPJ-T#scrollTo=SCFXYdbIXguc\n",
    "# 2. https://colab.research.google.com/drive/1YRHK4HO8RktGzlYmGjBo056kzVD4_j9o#scrollTo=BJR6t_gCQe_x\n",
    "\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Change here if use own drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "%cd drive/MyDrive\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)                          \n",
    "    np.random.seed(seed)                       \n",
    "    torch.manual_seed(seed)                    \n",
    "    torch.cuda.manual_seed(seed)               \n",
    "    torch.cuda.manual_seed_all(seed)           \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "setup_seed(42)\n",
    "\n",
    "train_df = pd.read_csv(\"binary_classification_training_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qFPjjYfbomGR"
   },
   "outputs": [],
   "source": [
    "# read in validation file\n",
    "validation_df = pd.read_csv(\"binary_classification_validation_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jrk0i9NXphLZ",
    "outputId": "39257dad-9060-4e25-af1d-fdb0367c718e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 19)\n",
      "Index(['Unnamed: 0', 'patent_number', 'decision', 'title', 'abstract',\n",
      "       'claims', 'background', 'summary', 'description', 'cpc_label',\n",
      "       'ipc_label', 'filing_date', 'examiner_id', 'output',\n",
      "       'application_invention_type', 'examiner_art_unit',\n",
      "       'small_entity_indicator', 'aia_first_to_file', 'foreign'],\n",
      "      dtype='object')\n",
      "(5000, 19)\n",
      "Index(['Unnamed: 0', 'patent_number', 'decision', 'title', 'abstract',\n",
      "       'claims', 'background', 'summary', 'description', 'cpc_label',\n",
      "       'ipc_label', 'filing_date', 'examiner_id', 'output',\n",
      "       'application_invention_type', 'examiner_art_unit',\n",
      "       'small_entity_indicator', 'aia_first_to_file', 'foreign'],\n",
      "      dtype='object')\n",
      "10000\n",
      "10000\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(train_df.columns)\n",
    "print(validation_df.shape)\n",
    "print(validation_df.columns)\n",
    "\n",
    "print(len(train_df[train_df[\"decision\"] == \"ACCEPTED\"]))\n",
    "print(len(train_df[train_df[\"decision\"] == \"REJECTED\"]))\n",
    "print(len(validation_df[validation_df[\"decision\"] == \"ACCEPTED\"]))\n",
    "print(len(validation_df[validation_df[\"decision\"] == \"REJECTED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WxoVJAHeruAm"
   },
   "outputs": [],
   "source": [
    "# Mapping the field output; 1 = ACCEPTED; 0 = REJECTED\n",
    "train_df['output'] = 1\n",
    "train_df.loc[train_df['decision'] == \"REJECTED\", 'output'] = 0\n",
    "\n",
    "validation_df['output'] = 1\n",
    "validation_df.loc[validation_df['decision'] == \"REJECTED\", 'output'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U3u6k02tVLG",
    "outputId": "c38de983-8293-4704-f9d4-396cf751eae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# check Rejected versus Accepted based on output field\n",
    "print(len(train_df[train_df[\"output\"] == 1]))\n",
    "print(len(train_df[train_df[\"output\"] == 0]))\n",
    "print(len(validation_df[validation_df[\"output\"] == 1]))\n",
    "print(len(validation_df[validation_df[\"output\"] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "u_2o9mrOthWx",
    "outputId": "bd859b41-671d-43b7-d72d-23ce140c064e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c6f5e0f1-5b2c-4eda-a312-8f387f6b0274\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>decision</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>background</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>cpc_label</th>\n",
       "      <th>ipc_label</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>examiner_id</th>\n",
       "      <th>output</th>\n",
       "      <th>application_invention_type</th>\n",
       "      <th>examiner_art_unit</th>\n",
       "      <th>small_entity_indicator</th>\n",
       "      <th>aia_first_to_file</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17944</td>\n",
       "      <td>15187583</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>FULLY INTEGRATED, DISPOSABLE TISSUE VISUALIZAT...</td>\n",
       "      <td>The present invention relates to a fully integ...</td>\n",
       "      <td>1-11. (canceled) 12. A sterilized, integrated,...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;1. Fiel...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;Embodiment...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>A61B107</td>\n",
       "      <td>A61B107</td>\n",
       "      <td>20160620</td>\n",
       "      <td>86346.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>3779</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1686</td>\n",
       "      <td>14906225</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>Compositions and Methods Comprising a Lipolyti...</td>\n",
       "      <td>The present invention provides lipolytic enzym...</td>\n",
       "      <td>1. A lipolytic enzyme variant or an active fra...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Lipolyt...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;The presen...</td>\n",
       "      <td>CROSS REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>C12N920</td>\n",
       "      <td>C12N920</td>\n",
       "      <td>20160119</td>\n",
       "      <td>68762.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1656</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3522</td>\n",
       "      <td>15012119</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>IMAGE DISPLAY DEVICE</td>\n",
       "      <td>An image display device of the present disclos...</td>\n",
       "      <td>1. An image display device comprising: a displ...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;1. Technical Field The p...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY &lt;EOH&gt;An image display device of ...</td>\n",
       "      <td>BACKGROUND 1. Technical Field The present disc...</td>\n",
       "      <td>G02B270172</td>\n",
       "      <td>G02B2701</td>\n",
       "      <td>20160201</td>\n",
       "      <td>99575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2626</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6639</td>\n",
       "      <td>15054201</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>ABUSE-PROOFED DOSAGE FORM</td>\n",
       "      <td>The invention relates to a dosage form that is...</td>\n",
       "      <td>1. An abuse-proofed dosage form thermoformed b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;SOH&gt; BRIEF DESCRIPTION OF THE DRAWING &lt;EOH&gt;FI...</td>\n",
       "      <td>This application is a continuation of U.S. Ser...</td>\n",
       "      <td>A61K31135</td>\n",
       "      <td>A61K31135</td>\n",
       "      <td>20160226</td>\n",
       "      <td>66231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1615</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18595</td>\n",
       "      <td>15108464</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>Process for the Preparation of Solid Particula...</td>\n",
       "      <td>A novel process for preparing vinyl aromatic p...</td>\n",
       "      <td>1. A process for the preparation of a solid pa...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Expanda...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;The object...</td>\n",
       "      <td>FIELD OF THE INVENTION The present invention r...</td>\n",
       "      <td>C08J920</td>\n",
       "      <td>C08J920</td>\n",
       "      <td>20160627</td>\n",
       "      <td>97379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1765</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6f5e0f1-5b2c-4eda-a312-8f387f6b0274')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c6f5e0f1-5b2c-4eda-a312-8f387f6b0274 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c6f5e0f1-5b2c-4eda-a312-8f387f6b0274');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  patent_number  decision  \\\n",
       "0       17944       15187583  ACCEPTED   \n",
       "1        1686       14906225  REJECTED   \n",
       "2        3522       15012119  REJECTED   \n",
       "3        6639       15054201  REJECTED   \n",
       "4       18595       15108464  ACCEPTED   \n",
       "\n",
       "                                               title  \\\n",
       "0  FULLY INTEGRATED, DISPOSABLE TISSUE VISUALIZAT...   \n",
       "1  Compositions and Methods Comprising a Lipolyti...   \n",
       "2                               IMAGE DISPLAY DEVICE   \n",
       "3                          ABUSE-PROOFED DOSAGE FORM   \n",
       "4  Process for the Preparation of Solid Particula...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The present invention relates to a fully integ...   \n",
       "1  The present invention provides lipolytic enzym...   \n",
       "2  An image display device of the present disclos...   \n",
       "3  The invention relates to a dosage form that is...   \n",
       "4  A novel process for preparing vinyl aromatic p...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  1-11. (canceled) 12. A sterilized, integrated,...   \n",
       "1  1. A lipolytic enzyme variant or an active fra...   \n",
       "2  1. An image display device comprising: a displ...   \n",
       "3  1. An abuse-proofed dosage form thermoformed b...   \n",
       "4  1. A process for the preparation of a solid pa...   \n",
       "\n",
       "                                          background  \\\n",
       "0  <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
       "1  <SOH> BACKGROUND OF THE INVENTION <EOH>Lipolyt...   \n",
       "2  <SOH> BACKGROUND <EOH>1. Technical Field The p...   \n",
       "3                                                NaN   \n",
       "4  <SOH> BACKGROUND OF THE INVENTION <EOH>Expanda...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <SOH> SUMMARY OF THE INVENTION <EOH>Embodiment...   \n",
       "1  <SOH> SUMMARY OF THE INVENTION <EOH>The presen...   \n",
       "2  <SOH> SUMMARY <EOH>An image display device of ...   \n",
       "3  <SOH> BRIEF DESCRIPTION OF THE DRAWING <EOH>FI...   \n",
       "4  <SOH> SUMMARY OF THE INVENTION <EOH>The object...   \n",
       "\n",
       "                                         description   cpc_label  ipc_label  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATIONS This a...     A61B107    A61B107   \n",
       "1  CROSS REFERENCE TO RELATED APPLICATIONS This a...     C12N920    C12N920   \n",
       "2  BACKGROUND 1. Technical Field The present disc...  G02B270172   G02B2701   \n",
       "3  This application is a continuation of U.S. Ser...   A61K31135  A61K31135   \n",
       "4  FIELD OF THE INVENTION The present invention r...     C08J920    C08J920   \n",
       "\n",
       "   filing_date  examiner_id  output application_invention_type  \\\n",
       "0     20160620      86346.0       1                    Utility   \n",
       "1     20160119      68762.0       0                    Utility   \n",
       "2     20160201      99575.0       0                    Utility   \n",
       "3     20160226      66231.0       0                    Utility   \n",
       "4     20160627      97379.0       1                    Utility   \n",
       "\n",
       "  examiner_art_unit small_entity_indicator aia_first_to_file  foreign  \n",
       "0              3779                  SMALL              true    False  \n",
       "1              1656           UNDISCOUNTED              true    False  \n",
       "2              2626           UNDISCOUNTED              true     True  \n",
       "3              1615           UNDISCOUNTED             false     True  \n",
       "4              1765           UNDISCOUNTED              true     True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check train_df\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "VSdgGHB1tjkI",
    "outputId": "df5b265c-9ab8-494a-fc52-dca1fbfa41ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-226b5c86-b975-45e6-a632-bd262c7fbf0f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>decision</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>background</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>cpc_label</th>\n",
       "      <th>ipc_label</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>examiner_id</th>\n",
       "      <th>output</th>\n",
       "      <th>application_invention_type</th>\n",
       "      <th>examiner_art_unit</th>\n",
       "      <th>small_entity_indicator</th>\n",
       "      <th>aia_first_to_file</th>\n",
       "      <th>foreign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>15227186</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>IMAGING DEVICE AND FOCUSING CONTROL METHOD</td>\n",
       "      <td>The present invention provides an imaging devi...</td>\n",
       "      <td>1. An imaging device comprising: an imaging el...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;1. Fiel...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;In all of ...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATIONS This a...</td>\n",
       "      <td>H04N523212</td>\n",
       "      <td>H04N5232</td>\n",
       "      <td>20160803</td>\n",
       "      <td>70534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2662.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003</td>\n",
       "      <td>15129780</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>FOIL REMOVAL DEVICE AND A METHOD FOR REMOVING ...</td>\n",
       "      <td>Provided is a foil removal device and a method...</td>\n",
       "      <td>1-26. (canceled) 27. A foil removal device for...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;The invention relates to...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;According ...</td>\n",
       "      <td>BACKGROUND The invention relates to a foil rem...</td>\n",
       "      <td>B65H19286</td>\n",
       "      <td>B65H1928</td>\n",
       "      <td>20160927</td>\n",
       "      <td>61755.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>811</td>\n",
       "      <td>15234229</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>FUNGICIDAL COMPOSITION COMPRISING A PYRIDYLETH...</td>\n",
       "      <td>A composition comprising at least a pyridyleth...</td>\n",
       "      <td>1.-20. (canceled) 21. A composition comprising...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Interna...</td>\n",
       "      <td>&lt;SOH&gt; SUMMARY OF THE INVENTION &lt;EOH&gt;Accordingl...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION(S) The ...</td>\n",
       "      <td>A01N4340</td>\n",
       "      <td>A01N4340</td>\n",
       "      <td>20160811</td>\n",
       "      <td>62399.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624</td>\n",
       "      <td>15233691</td>\n",
       "      <td>REJECTED</td>\n",
       "      <td>SEMICONDUCTOR MEMORY DEVICE</td>\n",
       "      <td>A semiconductor memory device includes a plura...</td>\n",
       "      <td>1. A semiconductor memory device comprising: a...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND &lt;EOH&gt;A NAND type flash memory...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION This ap...</td>\n",
       "      <td>G11C160483</td>\n",
       "      <td>G11C1604</td>\n",
       "      <td>20160810</td>\n",
       "      <td>62558.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3125</td>\n",
       "      <td>15125628</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>METHODS AND SYSTEMS FOR AUTOMATIC CREATION OF ...</td>\n",
       "      <td>Disclosed herein are methods and systems for a...</td>\n",
       "      <td>1. A method comprising: a first mobile radio b...</td>\n",
       "      <td>&lt;SOH&gt; BACKGROUND OF THE INVENTION &lt;EOH&gt;Million...</td>\n",
       "      <td>&lt;SOH&gt; BRIEF DESCRIPTION OF THE SEVERAL VIEWS O...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION Millions of people...</td>\n",
       "      <td>H04W408</td>\n",
       "      <td>H04W408</td>\n",
       "      <td>20160913</td>\n",
       "      <td>62652.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Utility</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>UNDISCOUNTED</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-226b5c86-b975-45e6-a632-bd262c7fbf0f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-226b5c86-b975-45e6-a632-bd262c7fbf0f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-226b5c86-b975-45e6-a632-bd262c7fbf0f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  patent_number  decision  \\\n",
       "0         149       15227186  ACCEPTED   \n",
       "1        4003       15129780  ACCEPTED   \n",
       "2         811       15234229  REJECTED   \n",
       "3         624       15233691  REJECTED   \n",
       "4        3125       15125628  ACCEPTED   \n",
       "\n",
       "                                               title  \\\n",
       "0         IMAGING DEVICE AND FOCUSING CONTROL METHOD   \n",
       "1  FOIL REMOVAL DEVICE AND A METHOD FOR REMOVING ...   \n",
       "2  FUNGICIDAL COMPOSITION COMPRISING A PYRIDYLETH...   \n",
       "3                        SEMICONDUCTOR MEMORY DEVICE   \n",
       "4  METHODS AND SYSTEMS FOR AUTOMATIC CREATION OF ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The present invention provides an imaging devi...   \n",
       "1  Provided is a foil removal device and a method...   \n",
       "2  A composition comprising at least a pyridyleth...   \n",
       "3  A semiconductor memory device includes a plura...   \n",
       "4  Disclosed herein are methods and systems for a...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  1. An imaging device comprising: an imaging el...   \n",
       "1  1-26. (canceled) 27. A foil removal device for...   \n",
       "2  1.-20. (canceled) 21. A composition comprising...   \n",
       "3  1. A semiconductor memory device comprising: a...   \n",
       "4  1. A method comprising: a first mobile radio b...   \n",
       "\n",
       "                                          background  \\\n",
       "0  <SOH> BACKGROUND OF THE INVENTION <EOH>1. Fiel...   \n",
       "1  <SOH> BACKGROUND <EOH>The invention relates to...   \n",
       "2  <SOH> BACKGROUND OF THE INVENTION <EOH>Interna...   \n",
       "3  <SOH> BACKGROUND <EOH>A NAND type flash memory...   \n",
       "4  <SOH> BACKGROUND OF THE INVENTION <EOH>Million...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  <SOH> SUMMARY OF THE INVENTION <EOH>In all of ...   \n",
       "1  <SOH> SUMMARY OF THE INVENTION <EOH>According ...   \n",
       "2  <SOH> SUMMARY OF THE INVENTION <EOH>Accordingl...   \n",
       "3                                                NaN   \n",
       "4  <SOH> BRIEF DESCRIPTION OF THE SEVERAL VIEWS O...   \n",
       "\n",
       "                                         description   cpc_label ipc_label  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATIONS This a...  H04N523212  H04N5232   \n",
       "1  BACKGROUND The invention relates to a foil rem...   B65H19286  B65H1928   \n",
       "2  CROSS-REFERENCE TO RELATED APPLICATION(S) The ...    A01N4340  A01N4340   \n",
       "3  CROSS-REFERENCE TO RELATED APPLICATION This ap...  G11C160483  G11C1604   \n",
       "4  BACKGROUND OF THE INVENTION Millions of people...     H04W408   H04W408   \n",
       "\n",
       "   filing_date  examiner_id  output application_invention_type  \\\n",
       "0     20160803      70534.0       1                    Utility   \n",
       "1     20160927      61755.0       1                    Utility   \n",
       "2     20160811      62399.0       0                    Utility   \n",
       "3     20160810      62558.0       0                    Utility   \n",
       "4     20160913      62652.0       1                    Utility   \n",
       "\n",
       "   examiner_art_unit small_entity_indicator aia_first_to_file  foreign  \n",
       "0             2662.0           UNDISCOUNTED              true     True  \n",
       "1             1745.0           UNDISCOUNTED              true     True  \n",
       "2             1627.0           UNDISCOUNTED             false     True  \n",
       "3             2824.0           UNDISCOUNTED              true     True  \n",
       "4             2648.0           UNDISCOUNTED              true    False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spot check train_df\n",
    "validation_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wyCXIT_Atn2v"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# PARAMETERS TO CHANGE HERE\n",
    "COLUMN = \"claims\"  # Change here to encode different columns of the dataset\n",
    "max_len = 512  \n",
    "MODEL = 'bert-base-uncased' # Change here to choose a different base model\n",
    "\n",
    "# Get the neccessary column values\n",
    "train_column_encoded = train_df[COLUMN].values  \n",
    "validation_column_encoded = validation_df[COLUMN].values\n",
    "\n",
    "input_ids_train = []       # Store the encoded input values\n",
    "attention_masks_train = [] # Store the encoded attention mask values\n",
    "\n",
    "input_ids_validation = []       # Store the encoded input values\n",
    "attention_masks_validation = [] # Store the encoded attention mask values\n",
    "\n",
    "# tokenizer function for train set\n",
    "def tokenize_patent_column_train(tokenizer):\n",
    "  for sentence in train_column_encoded:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,              \n",
    "                            max_length = max_len,.\n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,   \n",
    "                            return_tensors = 'pt',     \n",
    "                            ) \n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids_train.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_train.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# tokenizer function for validation set\n",
    "def tokenize_patent_column_validation(tokenizer):\n",
    "  for sentence in validation_column_encoded:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                            sentence,              \n",
    "                            max_length = max_len,  \n",
    "                            truncation = True,\n",
    "                            padding = 'max_length',\n",
    "                            return_attention_mask = True,   \n",
    "                            return_tensors = 'pt',     \n",
    "                            ) \n",
    "\n",
    "    input_ids_validation.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    attention_masks_validation.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "# Select which model being contemplated\n",
    "if (MODEL == 'bert-base-uncased'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)  \n",
    "elif (MODEL == 'distilbert-base-uncased'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)\n",
    "elif (MODEL == 'roberta-base'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)\n",
    "elif (MODEL == 'allenai/longformer-base-4096'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)\n",
    "elif (MODEL == 'allenai/scibert_scivocab_uncased'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained(MODEL, do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)\n",
    "elif (MODEL == 'SciBERTClassifier'):\n",
    "  tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True)\n",
    "  tokenize_patent_column_train(tokenizer)\n",
    "  tokenize_patent_column_validation(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IsIoWrFBt1hh"
   },
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "labels_train = torch.tensor(train_df['output'].values)\n",
    "input_ids_train = torch.stack(input_ids_train).squeeze()\n",
    "attention_masks_train = torch.stack(attention_masks_train).squeeze()\n",
    "\n",
    "labels_validation = torch.tensor(validation_df['output'].values)\n",
    "input_ids_validation = torch.stack(input_ids_validation).squeeze()\n",
    "attention_masks_validation = torch.stack(attention_masks_validation).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hj886aIet7gt"
   },
   "outputs": [],
   "source": [
    "# Implement the dataloader here\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# PARAMETERS TO CHANGE HERE\n",
    "batch_size = 16\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "h = torch.Generator()\n",
    "h.manual_seed(42)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle = True, generator = g)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(input_ids_validation, attention_masks_validation, labels_validation)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle = True, generator = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBZpvfh9t-am",
    "outputId": "571159e5-3f1c-4a73-db9e-171797e8481d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement the vanilla model here\n",
    "\n",
    "from transformers.models.cvt.modeling_cvt import CrossEntropyLoss\n",
    "from transformers import LongformerForSequenceClassification, RobertaForSequenceClassification, DistilBertForSequenceClassification, BertForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "model = None\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# SciBert defined here\n",
    "class SciBERTClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(SciBERTClassifier, self).__init__()\n",
    "        \n",
    "        self.SciBERT = BertModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.dropout_layer = nn.Dropout(0.25)\n",
    "        self.classification_layer = torch.nn.Linear(768, num_labels)        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels = None):\n",
    "        if labels == None:        \n",
    "          x = self.SciBERT(input_ids=input_ids)[1]\n",
    "          x = self.dropout_layer(x)          \n",
    "          logits = self.classification_layer(x)                    \n",
    "          return [logits]\n",
    "        else:\n",
    "          x = self.SciBERT(input_ids=input_ids)[1]          \n",
    "          x = self.dropout_layer(x)          \n",
    "          logits = self.classification_layer(x)                              \n",
    "          \n",
    "          loss_func = CrossEntropyLoss()\n",
    "          loss = loss_func(logits, labels)\n",
    "          return [loss]          \n",
    "\n",
    "\n",
    "if (MODEL == 'bert-base-uncased'):\n",
    "  model = BertForSequenceClassification.from_pretrained(\n",
    "      'bert-base-uncased', \n",
    "      num_labels = 2, \n",
    "                       \n",
    "      output_attentions = False, \n",
    "      output_hidden_states = False, \n",
    "  )\n",
    "\n",
    "elif (MODEL == 'distilbert-base-uncased'):\n",
    "  model = DistilBertForSequenceClassification.from_pretrained(\n",
    "      'distilbert-base-uncased', \n",
    "      num_labels = 2, \n",
    "      output_attentions = False, \n",
    "      output_hidden_states = False, \n",
    "  )\n",
    "elif (MODEL == 'roberta-base'):\n",
    "  model = RobertaForSequenceClassification.from_pretrained(\n",
    "      'roberta-base', \n",
    "      num_labels = 2, \n",
    "      output_attentions = False,\n",
    "      output_hidden_states = False, \n",
    "  )\n",
    "elif (MODEL == 'allenai/longformer-base-4096'):\n",
    "  model = LongformerForSequenceClassification.from_pretrained(\n",
    "      'allenai/longformer-base-4096', \n",
    "      num_labels = 2, \n",
    "      output_attentions = False, \n",
    "      output_hidden_states = False, \n",
    "  )\n",
    "elif (MODEL == 'SciBERTClassifier'):\n",
    "  model = SciBERTClassifier(num_labels = 2)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bhol-r1kuDj0",
    "outputId": "834b8dc2-0577-44b8-b9e3-53a3d62bd02d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# PARAMETERS TO CHANGE HERE\n",
    "epochs = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UYpJ_xHSuFVI"
   },
   "outputs": [],
   "source": [
    "# Accuracy and time elapsed calculation\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Implement F1 Score\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()        \n",
    "\n",
    "    labels_flat = labels.flatten()\n",
    "        \n",
    "    # Change this part to calculate accuracy\n",
    "    accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    # accuracy: 0\n",
    "    # pred_flat: 1\n",
    "    # labels_flat: 2\n",
    "    return_package = [accuracy, pred_flat, labels_flat]\n",
    "    \n",
    "    return return_package\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sGCNTQ9uHUL",
    "outputId": "0893c90b-65c7-4df7-f4e7-178ab9bae12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.8/dist-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: A100-SXM4-40GB\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6666)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.5000)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.9996)\n",
      "  Accuracy: 0.50000\n",
      "  Validation took: 0:00:37\n",
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.67095\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6865)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.5849)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.8308)\n",
      "  Accuracy: 0.62061\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:28.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.63397\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6221)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6575)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5904)\n",
      "  Accuracy: 0.64157\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:57.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:12.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.59473\n",
      "  Training epoch took: 0:07:45\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6893)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6050)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.8008)\n",
      "  Accuracy: 0.63938\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:14.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:12.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.53158\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6464)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6095)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6880)\n",
      "  Accuracy: 0.62340\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:28.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.44546\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6323)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6196)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.6456)\n",
      "  Accuracy: 0.62480\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:12.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.35242\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.5817)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6283)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5416)\n",
      "  Accuracy: 0.61062\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:14.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:12.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.27210\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6068)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6180)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5960)\n",
      "  Accuracy: 0.61382\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:59.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.21588\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.6013)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6039)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5988)\n",
      "  Accuracy: 0.60264\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:15.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:44.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:13.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.17292\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.5711)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6142)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5336)\n",
      "  Accuracy: 0.59884\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of  1,250.    Elapsed: 0:00:15.\n",
      "  Batch    80  of  1,250.    Elapsed: 0:00:30.\n",
      "  Batch   120  of  1,250.    Elapsed: 0:00:45.\n",
      "  Batch   160  of  1,250.    Elapsed: 0:01:00.\n",
      "  Batch   200  of  1,250.    Elapsed: 0:01:14.\n",
      "  Batch   240  of  1,250.    Elapsed: 0:01:29.\n",
      "  Batch   280  of  1,250.    Elapsed: 0:01:44.\n",
      "  Batch   320  of  1,250.    Elapsed: 0:01:59.\n",
      "  Batch   360  of  1,250.    Elapsed: 0:02:14.\n",
      "  Batch   400  of  1,250.    Elapsed: 0:02:29.\n",
      "  Batch   440  of  1,250.    Elapsed: 0:02:44.\n",
      "  Batch   480  of  1,250.    Elapsed: 0:02:59.\n",
      "  Batch   520  of  1,250.    Elapsed: 0:03:14.\n",
      "  Batch   560  of  1,250.    Elapsed: 0:03:29.\n",
      "  Batch   600  of  1,250.    Elapsed: 0:03:43.\n",
      "  Batch   640  of  1,250.    Elapsed: 0:03:58.\n",
      "  Batch   680  of  1,250.    Elapsed: 0:04:13.\n",
      "  Batch   720  of  1,250.    Elapsed: 0:04:28.\n",
      "  Batch   760  of  1,250.    Elapsed: 0:04:43.\n",
      "  Batch   800  of  1,250.    Elapsed: 0:04:58.\n",
      "  Batch   840  of  1,250.    Elapsed: 0:05:13.\n",
      "  Batch   880  of  1,250.    Elapsed: 0:05:28.\n",
      "  Batch   920  of  1,250.    Elapsed: 0:05:43.\n",
      "  Batch   960  of  1,250.    Elapsed: 0:05:58.\n",
      "  Batch 1,000  of  1,250.    Elapsed: 0:06:12.\n",
      "  Batch 1,040  of  1,250.    Elapsed: 0:06:27.\n",
      "  Batch 1,080  of  1,250.    Elapsed: 0:06:42.\n",
      "  Batch 1,120  of  1,250.    Elapsed: 0:06:57.\n",
      "  Batch 1,160  of  1,250.    Elapsed: 0:07:12.\n",
      "  Batch 1,200  of  1,250.    Elapsed: 0:07:27.\n",
      "  Batch 1,240  of  1,250.    Elapsed: 0:07:42.\n",
      "\n",
      "  Average training loss: 0.14069\n",
      "  Training epoch took: 0:07:46\n",
      "\n",
      "Running Initial Validation...\n",
      ">>>>>>>>>>> F1 Score:  tensor(0.5790)\n",
      ">>>>>>>>>>> Precision Score: tensor(0.6041)\n",
      ">>>>>>>>>>> Recall Score:  tensor(0.5560)\n",
      "  Accuracy: 0.59545\n",
      "  Validation took: 0:00:36\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "!pip install torchmetrics\n",
    "\n",
    "import random\n",
    "\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall\n",
    "\n",
    "# Set device to GPU:\n",
    "device = None\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    target_list = []\n",
    "    output_list = []\n",
    "\n",
    "    # Initial Validation\n",
    "\n",
    "\n",
    "    if(epoch_i == 0):\n",
    "      print(\"\")\n",
    "      print(\"Running Initial Validation...\")\n",
    "\n",
    "      t0 = time.time()\n",
    "\n",
    "      model.eval()\n",
    "\n",
    "      # Init variables for tracking \n",
    "      eval_loss, eval_accuracy = 0, 0\n",
    "      nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "      # Evaluate data for one epoch\n",
    "      for batch in validation_dataloader:\n",
    "          \n",
    "          # Add batch to GPU\n",
    "          batch = tuple(t.to(device) for t in batch)\n",
    "          \n",
    "          # Unpack the inputs from our dataloader\n",
    "          b_input_ids, b_input_mask, b_labels = batch\n",
    "          \n",
    "          with torch.no_grad():        \n",
    "              \n",
    "              outputs = model(b_input_ids, \n",
    "                              attention_mask=b_input_mask)\n",
    "          \n",
    "          logits = outputs[0]\n",
    "\n",
    "          # Move logits and labels to CPU\n",
    "          logits = logits.detach().cpu().numpy()\n",
    "          label_ids = b_labels.to('cpu').numpy()\n",
    "          \n",
    "          # Calculate the accuracy for this batch of test sentences.\n",
    "          return_values = flat_accuracy(logits, label_ids)   \n",
    "          \n",
    "          eval_accuracy += return_values[0]\n",
    "          output_list.append(return_values[1]) \n",
    "          target_list.append(return_values[2])   \n",
    "        \n",
    "          nb_eval_steps += 1   \n",
    "\n",
    "      outputs_concat = torch.tensor(np.concatenate(output_list))  \n",
    "      targets_concat = torch.tensor(np.concatenate(target_list))      \n",
    "        \n",
    "      metric = BinaryF1Score()\n",
    "      print(\">>>>>>>>>>> F1 Score: \", metric(outputs_concat, targets_concat))\n",
    "\n",
    "      metric1 = BinaryPrecision()\n",
    "      print(\">>>>>>>>>>> Precision Score:\", metric1(outputs_concat, targets_concat))\n",
    "\n",
    "      metric2 = BinaryRecall()\n",
    "      print(\">>>>>>>>>>> Recall Score: \", metric2(outputs_concat, targets_concat))\n",
    "                \n",
    "      # Report the final accuracy for this validation run.\n",
    "      print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
    "      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "      # Reset target output list to none again\n",
    "      target_list = []\n",
    "      output_list = []\n",
    "      outputs_concat = None\n",
    "      targets_concat = None\n",
    "    \n",
    "    # Training\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.    \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "      \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "               \n",
    "        loss = outputs[0]\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # Validation\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Initial Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Init variables for tracking \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "        \n",
    "            outputs = model(b_input_ids, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Accuracy calculation\n",
    "        return_values = flat_accuracy(logits, label_ids)                          \n",
    "        eval_accuracy += return_values[0]\n",
    "        output_list.append(return_values[1]) \n",
    "        target_list.append(return_values[2])   \n",
    "      \n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    outputs_concat = torch.tensor(np.concatenate(output_list))  \n",
    "    targets_concat = torch.tensor(np.concatenate(target_list))\n",
    "      \n",
    "    metric = BinaryF1Score()\n",
    "    print(\">>>>>>>>>>> F1 Score: \", metric(outputs_concat, targets_concat))\n",
    "\n",
    "    metric1 = BinaryPrecision()\n",
    "    print(\">>>>>>>>>>> Precision Score:\", metric1(outputs_concat, targets_concat))\n",
    "\n",
    "    metric2 = BinaryRecall()\n",
    "    print(\">>>>>>>>>>> Recall Score: \", metric2(outputs_concat, targets_concat))\n",
    "              \n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # Reset target output list to none again\n",
    "    target_list = []\n",
    "    output_list = []\n",
    "   \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
